{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os; from os import listdir; from os.path import isfile, join\n",
    "import re  \n",
    "#from skimage import io \n",
    "from skimage.io import imread\n",
    "# To manipulate arrays\n",
    "import numpy as np \n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pathlib\n",
    "import sys\n",
    "from skimage.exposure import rescale_intensity\n",
    "import rsnapsim as rss\n",
    "from skimage.measure import find_contours\n",
    "# Plotting\n",
    "import matplotlib as mpl ; import matplotlib.pyplot as plt \n",
    "# To create interactive elements\n",
    "import ipywidgets as widgets ; from ipywidgets import interact, interactive, fixed, interact_manual, Button, HBox, VBox, Layout, GridspecLayout ; from IPython.display import Image\n",
    "\n",
    "import dna_features_viewer\n",
    "from dna_features_viewer import BiopythonTranslator, GraphicFeature, GraphicRecord, CircularGraphicRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Deffining directories\n",
    "current_dir = pathlib.Path().absolute()\n",
    "sequences_dir = current_dir.parents[1].joinpath('DataBases','gene_files')\n",
    "video_dir = current_dir.parents[1].joinpath('DataBases','videos_for_sim_cell')\n",
    "#trajectories_dir = current_dir.parents[1].joinpath('DataBases','rsnapsim_simulations','bactin_ssa.npy')\n",
    "trajectories_dir = current_dir.parents[1].joinpath('DataBases','rsnapsim_simulations','kdm5b_ssa.npy')\n",
    "rsnaped_dir = current_dir.parents[1].joinpath('rsnaped')\n",
    "gene_file = current_dir.parents[1].joinpath('DataBases','gene_files','KDM5B_withTags.txt')\n",
    "masks_dir = current_dir.parents[1].joinpath('DataBases','masks_for_sim_cell')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to dropbox\n",
    "from sys import platform as _platform\n",
    "if _platform == \"linux\" or _platform == \"linux2\":\n",
    "    dropbox_address = pathlib.Path('/','home','luisub','Dropbox', 'Project_rSNAPed','manuscript','Figures')\n",
    "elif _platform == \"darwin\":\n",
    "    dropbox_address = pathlib.Path('/','Users','luisaguilera','Dropbox', 'Project_rSNAPed','manuscript','Figures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing rSNAPed\n",
    "sys.path.append(str(rsnaped_dir))\n",
    "import rsnaped as rsp\n",
    "#from rsnaped import rsnaped as rsp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dna_features_viewer import BiopythonTranslator\n",
    "class MyCustomTranslator(BiopythonTranslator):\n",
    "    \"\"\"Custom translator\n",
    "    \"\"\"\n",
    "    def compute_feature_color(self, feature):\n",
    "        if feature.type == \"CDS\":\n",
    "            return \"#57B956\"\n",
    "        elif feature.type == \"FLAG\":\n",
    "            return \"#ff0000\"\n",
    "        elif feature.type == \"MS2\":\n",
    "            return \"#098BF5\"\n",
    "        elif feature.type == \"PP7\": \n",
    "            return \"#EB5559\"\n",
    "        else:\n",
    "            return \"#C4B07B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plasmid sequences\n",
    "gene_file_pUB_SM_KDM5B_PP7 = str(sequences_dir.joinpath('kdm5b.gb')) # plasmid pUB_SM_KDM5B_PP7 \n",
    "graphic_record = MyCustomTranslator().translate_record(gene_file_pUB_SM_KDM5B_PP7) \n",
    "ax, _ = graphic_record.plot(figure_width=20, strand_in_label_threshold=7)\n",
    "#ax.set_title('pUB_SM_KDM5B_PP7 (1895 codons)')\n",
    "graphic_record.plot_legend(ax=ax, loc=1, ncol=3, frameon=False)\n",
    "name_figure = 'sequence.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "ax.figure.savefig(figure_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = (2.5, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters that need to be tested. \n",
    "number_of_simulated_cells = 1 # PLEASE TEST MIN 1 MAX 10\n",
    "number_spots_per_cell = 50     # PLEASE TEST MIN 5 MAX 200\n",
    "simulation_time_in_sec = 200     # PLEASE TEST MIN 10 MAX 100\n",
    "diffusion_coefficient = 0.5    # PLEASE TEST MIN 0.1 MAX 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "intensity_calculation_method = 'disk_donut'  # options are : 'total_intensity' and 'disk_donut' 'gaussian_fit'\n",
    "mask_selection_method = 'max_area' # options are : 'max_spots' and 'max_area' \n",
    "use_optimization_for_tracking = 1 # 0 not using, 1 is using optimization\n",
    "frame_selection_empty_video = 'shuffle' # Options are: 'constant' , 'shuffle' and 'loop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "particle_size = 7 # spot size for the simulation and tracking.\n",
    "elongation_rate = 10\n",
    "initiation_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_scale_ch0 = 200\n",
    "intensity_scale_ch1 = 200\n",
    "intensity_scale_ch2 = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_detection_size = particle_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsnapsim_ssa(gene_file,ke,ki,frames=300,frame_rate=1,n_traj=20):\n",
    "    '''\n",
    "    This function uses rsnapsim to simulate the single-molecule translation dynamics of any gene.\n",
    "    Inputs:\n",
    "    gene_file : str, with the location of a fasta file.\n",
    "    ke : float, elongation rate.\n",
    "    ki: float, initiation rate.\n",
    "    frames: int, total number of simulation frames in seconds.\n",
    "    n_traj: int, number of trajectories to simulate\n",
    "    frame_rate : int, frame rate per second\n",
    "    Outputs:\n",
    "    ssa_int : NumPy array with dimensions [Time_points, simulated_trajectories]\n",
    "    '''\n",
    "    poi_strs, poi_objs, tagged_pois,raw_seq = rss.seqmanip.open_seq_file(str(gene_file))\n",
    "    gene_obj = tagged_pois['1'][0]\n",
    "    gene_obj.ke_mu = ke\n",
    "    rss.solver.protein = gene_obj #pass the protein object\n",
    "    t_burnin = 1000\n",
    "    t = np.linspace(0,t_burnin+frames,(t_burnin+frames+1)*(frame_rate))\n",
    "    number_probes = np.amax(gene_obj.probe_vec)\n",
    "    ints = []\n",
    "    #for i in tq.tqdm(range(n_traj)):\n",
    "    counter = 0\n",
    "    while counter < n_traj:\n",
    "      ssa_solution = rss.solver.solve_ssa(gene_obj.kelong, t, ki=ki, kt = ke, low_memory=True,record_stats=False,n_traj=1)\n",
    "      ssa_int =  ssa_solution.intensity_vec[0,t_burnin*frame_rate:-1,:]\n",
    "      if np.mean(ssa_int)> 1:\n",
    "        ints.append(ssa_int)\n",
    "        counter +=1\n",
    "    ssa = np.array(ints).reshape(n_traj,frames) #flatten the lists back to a numpy array\n",
    "    ssa_ump = ssa/number_probes\n",
    "    return ssa, ssa_ump, gene_obj, t,number_probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_simulated_cells(current_dir, video_dir,masks_dir=None, ke=3,ki=0.03,gene_file =None, trajectories_dir=None, number_of_simulated_cells=3,number_spots_per_cell=80,simulation_time_in_sec =100,step_size_in_sec=1,particle_size=5, diffusion_coefficient =1,path_to_rSNAPsim= None, path_to_save_output='temp',intensity_calculation_method='gaussian_fit',frame_selection_empty_video=frame_selection_empty_video):\n",
    "    spot_size = particle_size\n",
    "    spot_sigma = 1\n",
    "    # Code that creates the folder to store results.\n",
    "    diffusion_coefficient_string = str(diffusion_coefficient).replace('.','_')\n",
    "    directory_name = 'Simulation_V2__'+'ns_'+str(number_spots_per_cell) +'_diff_'+ diffusion_coefficient_string \n",
    "    path_to_save_output = 'temp'\n",
    "    save_to_path =  current_dir.joinpath(path_to_save_output , directory_name )\n",
    "    if not os.path.exists(str(save_to_path)):\n",
    "        os.makedirs(str(save_to_path))\n",
    "    else:\n",
    "        shutil.rmtree(str(save_to_path))\n",
    "        os.makedirs(str(save_to_path))\n",
    "    counter = 0\n",
    "    ## Main loop that creates each cell and dataframe\n",
    "    for cell_number in range (0, number_of_simulated_cells):\n",
    "        output_directory_name = str(video_dir)\n",
    "        list_files_names = sorted([f for f in listdir(output_directory_name) if isfile(join(output_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "        list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "        path_files = [ str(video_dir.joinpath(f).resolve()) for f in list_files_names ] # creating the complete path for each file\n",
    "        selected_video = 7 \n",
    "        video_path = path_files[selected_video]        \n",
    "        video = imread(video_path) \n",
    "        # Reducing in a half the intensity in the original video\n",
    "        video = video//2\n",
    "        empty_videos = video\n",
    "        counter +=1\n",
    "        \n",
    "        # Loading the mask image\n",
    "        if not (masks_dir is None):\n",
    "            masks_dir=masks_dir.joinpath('mask_cell_shape_'+str(selected_video)+'.tif')\n",
    "            mask_image = imread(str(masks_dir))\n",
    "        else:\n",
    "            mask_image = None\n",
    "        \n",
    "        if counter>=len(path_files):\n",
    "            counter =0\n",
    "        if not (trajectories_dir is None ):\n",
    "            # Loading trajectories from file\n",
    "            ssa_trajectories = np.load(str(trajectories_dir))\n",
    "            random_index_ch0 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "            random_index_ch1 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "            random_index_ch2 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "            simulated_trajectories_ch0 = ssa_trajectories[random_index_ch0,0:simulation_time_in_sec:step_size_in_sec]\n",
    "            simulated_trajectories_ch1 = ssa_trajectories[random_index_ch1,0:simulation_time_in_sec:step_size_in_sec]\n",
    "            simulated_trajectories_ch2 =  ssa_trajectories[random_index_ch2,0:simulation_time_in_sec:step_size_in_sec]\n",
    "        else:\n",
    "            # Simulations for intensity\n",
    "            ssa1,ssa1_ump,_,_,number_probes = rsnapsim_ssa(gene_file,ke,ki,frames=simulation_time_in_sec,frame_rate=1,n_traj=number_spots_per_cell) # rss.ssa_solver(n_traj = number_spots_per_cell, start_time=starting_time,tf=starting_time+n_frames, tstep=starting_time+n_frames,k_elong_mean=3, k_initiation=.03)  # tstep = total number of steps including the burnin time \n",
    "            simulated_trajectories_ch1 = ssa1_ump\n",
    "            ssa2,ssa2_ump,_,_,number_probes =  rsnapsim_ssa(gene_file,ke,ki,frames=simulation_time_in_sec,frame_rate=1,n_traj=number_spots_per_cell) # rss.ssa_solver(n_traj = number_spots_per_cell, start_time=starting_time,tf=starting_time+n_frames, tstep=starting_time+n_frames,k_elong_mean=3, k_initiation=.03)  # tstep = total number of steps including the burnin time \n",
    "            simulated_trajectories_ch2 = ssa2_ump\n",
    "            simulated_trajectories_ch0 = simulated_trajectories_ch1\n",
    "        #simulated_trajectories_ch0 = None\n",
    "        # Running the cell simulation\n",
    "        saved_file_name = str(save_to_path.joinpath('sim_cell_'+str(cell_number)))\n",
    "        tensor_video , spot_positions_movement, DataFrame_particles_intensities = rsp.SimulatedCell( base_video=video, mask_image=mask_image,number_spots = number_spots_per_cell, number_frames=simulation_time_in_sec, step_size=step_size_in_sec, diffusion_coefficient =diffusion_coefficient, simulated_trajectories_ch0=simulated_trajectories_ch0, size_spot_ch0=spot_size, spot_sigma_ch0=spot_sigma, simulated_trajectories_ch1=simulated_trajectories_ch1, size_spot_ch1=spot_size, spot_sigma_ch1=spot_sigma, simulated_trajectories_ch2=simulated_trajectories_ch2, size_spot_ch2=spot_size, spot_sigma_ch2=spot_sigma, ignore_ch0=0,ignore_ch1=0, ignore_ch2=1,save_as_tif_uint8=0,save_as_tif =1,save_as_gif=0, save_dataframe=1, saved_file_name=saved_file_name,create_temp_folder = False, intensity_calculation_method=intensity_calculation_method,perform_video_augmentation=0,frame_selection_empty_video=frame_selection_empty_video ,intensity_scale_ch0 = intensity_scale_ch0,intensity_scale_ch1 = intensity_scale_ch1,intensity_scale_ch2 = intensity_scale_ch2).make_simulation()      \n",
    "        #print ('The results are saved in folder: ', saved_file_name)\n",
    "    return save_to_path, simulated_trajectories_ch0, simulated_trajectories_ch1, simulated_trajectories_ch2, empty_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the simulation\n",
    "start = timer()\n",
    "output_directory_name, simulated_trajectories_ch0, simulated_trajectories_ch1, simulated_trajectories_ch2, empty_videos = fun_simulated_cells(current_dir,video_dir,masks_dir,ke=elongation_rate, ki=initiation_rate,trajectories_dir=None,gene_file= gene_file, number_of_simulated_cells=number_of_simulated_cells,number_spots_per_cell=number_spots_per_cell,simulation_time_in_sec =simulation_time_in_sec,step_size_in_sec=1,particle_size=particle_size, diffusion_coefficient=diffusion_coefficient,path_to_rSNAPsim= None,intensity_calculation_method=intensity_calculation_method,frame_selection_empty_video=frame_selection_empty_video)\n",
    "end = timer()\n",
    "print('Time to generate simulated data:',round(end - start), ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = str(output_directory_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reads the folder with the results and import the simulations as lists\n",
    "list_files_names = sorted([f for f in listdir(output_directory_name) if isfile(join(output_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files = [ str(output_directory_name.joinpath(f).resolve()) for f in list_files_names ] # creating the complete path for each file\n",
    "\n",
    "# Reading the microscopy data\n",
    "list_videos_original = [imread(f)[:,:,:,:] for f in  path_files] # List with all the videos\n",
    "nimg = number_of_simulated_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling images\n",
    "rescale_video = False\n",
    "if rescale_video == True:\n",
    "    list_videos = []\n",
    "    number_channels = list_videos_original[0].shape[-1]\n",
    "    number_z_slices = list_videos_original[0].shape[0]\n",
    "    for i in range (0,nimg ):\n",
    "        temp_img = np.zeros_like(list_videos_original[0])\n",
    "        for j in range(0,number_channels):\n",
    "            temp_img[:,:,:,j] =  np.asarray( [ rescale_intensity(list_videos_original[i][z,:,:,j], in_range='image', out_range='dtype')  for z in range (0, number_z_slices)]  )\n",
    "        list_videos.append(temp_img)\n",
    "else:\n",
    "    list_videos = list_videos_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reads the dataframes\n",
    "list_files_dfnames = sorted([f for f in listdir(output_directory_name) if isfile(join(output_directory_name, f)) and ('.csv') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_dfnames.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files_df = [ str(output_directory_name.joinpath(f).resolve()) for f in list_files_dfnames ] # creating the complete path for each file\n",
    "list_df_real_positions = [pd.read_csv(f) for f in  path_files_df] # List with all the videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the simulated images\n",
    "#rsp.VisualizerImage(list_videos,list_files_names=list_files_names,selected_channel =0,selected_timepoint= 0,normalize=0,individual_figure_size=7).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "selected_timePoint = 0\n",
    "channel = 1\n",
    "plt.imshow(empty_videos[selected_timePoint,:,:,channel],cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "name_figure = 'empty.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.tight_layout() \n",
    "plt.savefig(figure_directory, transparent=True,dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "selected_timePoint = 0\n",
    "channel = 1\n",
    "plt.imshow(list_videos[0][selected_timePoint,:,:,channel],cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "name_figure = 'simulated.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.tight_layout() \n",
    "plt.savefig(figure_directory, transparent=True,dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rsp.VisualizerImage(list_videos,list_selected_particles_dataframe = list_df_real_positions,list_files_names=list_files_names,selected_channel =0,selected_timepoint= 0,normalize=0,individual_figure_size=7).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intensity_selection_method =intensity_selection_method, mask_selection_method = mask_selection_method\n",
    "list_DataFrame_particles_intensities= []\n",
    "list_array_intensities = []\n",
    "list_time_vector = []\n",
    "for i in tqdm(range(0,nimg)): \n",
    "    DataFrame_particles_intensities, array_intensities, time_vector, mean_intensities,std_intensities, mean_intensities_normalized, std_intensities_normalized = rsp.PipelineTracking(list_videos[i],particle_size=particle_detection_size,file_name=list_files_names[i],selected_channel=0,intensity_calculation_method =intensity_calculation_method, mask_selection_method = mask_selection_method,show_plot=1,use_optimization_for_tracking=use_optimization_for_tracking,real_positions_dataframe = list_df_real_positions[i],average_cell_diameter=200,print_process_times=1).run()    \n",
    "    list_DataFrame_particles_intensities.append(DataFrame_particles_intensities)\n",
    "    list_array_intensities.append(array_intensities)\n",
    "    list_time_vector.append(time_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_channel =1\n",
    "selected_masks = rsp.Cellpose(list_videos[0][0,:,:,selected_channel], num_iterations = 10, selection_method = 'max_area', diameter = 220 ).calculate_masks() # options are 'max_area' or 'max_cells'\n",
    "selected_mask  = rsp.CellposeSelection(selected_masks, list_videos[0], selection_method = mask_selection_method, particle_size = particle_size, selected_channel = selected_channel).select_mask()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_array(dataframe_simulated_cell):\n",
    "    '''\n",
    "    This function takes the dataframe and extracts the information from it. \n",
    "    Information is separated by particles. Notice that dataframe contains information about 600 particles.\n",
    "\n",
    "    Input\n",
    "        dataframe_simulated_cell : pandas dataframe\n",
    "\n",
    "    Returns\n",
    "        I_g : Intensities for each particle in the green channel. NumPy array with dimensions [number_particles, time_points]\n",
    "        I_g_std : Std for the intensities for each particle in the green channel.  NumPy array with dimensions [number_particles, time_points]\n",
    "        I_r : Intensities for each particle in the red channel. NumPy array with dimensions [number_particles, time_points]\n",
    "        I_r_std : Std for the intensities for each particle in the red channel. NumPy array with dimensions [number_particles, time_points]\n",
    "        x_loc : x position for each particle in the dataframe. NumPy array with dimensions [number_particles, time_points]\n",
    "        y_loc : y position for each particle in the dataframe. NumPy array with dimensions [number_particles, time_points]\n",
    "  \n",
    "    '''\n",
    "    # get the total number of particles in all cells\n",
    "    total_particles = 0\n",
    "    for cell in set(dataframe_simulated_cell['cell_number']):\n",
    "        total_particles += len(set(dataframe_simulated_cell[dataframe_simulated_cell['cell_number'] == 0]['particle'] ))\n",
    "\n",
    "    #preallocate numpy array sof n_particles by nframes\n",
    "    I_g = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] )  #intensity green\n",
    "    I_g_std = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] ) #intensity green std\n",
    "    x_loc = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] ) #x loc\n",
    "    y_loc = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] ) #y_loc\n",
    "    I_r_std   = np.zeros([total_particles, (np.max(dataframe_simulated_cell['frame'])+1)] ) #intensity red\n",
    "    I_r = np.zeros([total_particles, (np.max(dataframe_simulated_cell['frame'])+1) ] ) #intensity red std\n",
    "    k = 0\n",
    "\n",
    "    # For loops that iterate for each particle and stores the data in the previously pre-alocated arrays.\n",
    "    for cell in set(dataframe_simulated_cell['cell_number']):  #for every cell \n",
    "        for particle in set(dataframe_simulated_cell[dataframe_simulated_cell['cell_number'] == 0]['particle'] ): #for every particle\n",
    "            tmpdf = dataframe_simulated_cell[(dataframe_simulated_cell['cell_number'] == cell) & (dataframe_simulated_cell['particle'] == particle)]  #slice the dataframe\n",
    "            maxframe = np.max(tmpdf['frame'])\n",
    "            minframe = np.min(tmpdf['frame'])\n",
    "            I_g[k, 0:(maxframe+1-minframe)] = tmpdf['green_int_mean']  #fill the arrays to return out\n",
    "            x_loc[k, 0:(maxframe+1-minframe)] = tmpdf['x']\n",
    "            y_loc[k, 0:(maxframe+1-minframe)] = tmpdf['y']\n",
    "            I_g_std[k, 0:(maxframe+1-minframe)] = tmpdf['green_int_std']\n",
    "            I_r[k, 0:(maxframe+1-minframe)] = tmpdf['red_int_mean']\n",
    "            I_r_std[k, 0:(maxframe+1-minframe)] = tmpdf['red_int_std']\n",
    "            k+=1 #iterate over k (total particles)\n",
    "    return I_g, I_g_std, I_r, I_r_std, x_loc,y_loc   #return everything backout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing intensity distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"Real\" intensities from SSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_timepoint = 0 #simulation_time_in_sec-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extrema(vector,min_percentile = 0.1 ,max_percentile = 99.):\n",
    "    '''This function is intended to remove extrema data given by the min and max percentiles specified by the user'''\n",
    "    vector = vector [vector>0]\n",
    "    max_val = np.percentile(vector, max_percentile)\n",
    "    min_val =  np.percentile(vector, min_percentile)\n",
    "    print(round(min_val,2),round(max_val,2))\n",
    "    new_vector = vector [vector< max_val] # = np.percentile(vector,max_percentile)\n",
    "    new_vector = new_vector [new_vector> min_val] # = np.percentile(vector, min_percentile)\n",
    "    return new_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssa_trajectories = np.load(str(trajectories_dir))\n",
    "ssa_trajectories_timePoint = ssa_trajectories[:,sel_timepoint].flatten()\n",
    "ssa_trajectories_timePoint= remove_extrema(ssa_trajectories_timePoint)\n",
    "ssa_trajectories_timePoint_normalized = (ssa_trajectories_timePoint-np.amin(ssa_trajectories_timePoint))/ (np.amax(ssa_trajectories_timePoint)-np.amin(ssa_trajectories_timePoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovered intensities from tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells_green_int = np.array([])\n",
    "for i in range(0,nimg): \n",
    "    all_cells_green_int = np.append(all_cells_green_int,list_array_intensities[i][:,sel_timepoint,1].flatten())   \n",
    "all_cells_green_int = all_cells_green_int[all_cells_green_int>0]\n",
    "all_cells_green_int= remove_extrema(all_cells_green_int)\n",
    "all_cells_green_int_normalized = (all_cells_green_int-np.amin(all_cells_green_int))/ (np.amax(all_cells_green_int)-np.amin(all_cells_green_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading intensities from image. \"Perfect tracking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the number of real simulations from folder name\n",
    "path_str = str(output_directory_name)                    # path\n",
    "ind_str_start = path_str.find('_ns_') +4                # start index in string\n",
    "ind_str_end = path_str.find('_diff')                    # end index in string\n",
    "max_nspots = int(path_str[ind_str_start:ind_str_end])   # number of spots per cell\n",
    "\n",
    "#Pre-alocating memory\n",
    "intensity_values_in_image = np.zeros((nimg,max_nspots)) # prealocating memory for intentiy\n",
    "\n",
    "for i in range(0,nimg):\n",
    "    for j in range (0,max_nspots):\n",
    "        file_name = str(output_directory_name.joinpath('sim_cell_'+str(i)+'_df.csv'))\n",
    "        df_intensities_real = pd.read_csv(file_name)  \n",
    "        intensity_values_in_image[i,j] = df_intensities_real[df_intensities_real['particle'] ==j].green_int_mean.values[sel_timepoint] \n",
    "intensity_values_in_image_flat = intensity_values_in_image.flatten()\n",
    "intensity_values_in_image_flat =  intensity_values_in_image_flat[intensity_values_in_image_flat>0]\n",
    "intensity_values_in_image_flat= remove_extrema(intensity_values_in_image_flat)\n",
    "intensity_values_in_image_normalized = (intensity_values_in_image_flat-np.amin(intensity_values_in_image_flat))/ (np.amax(intensity_values_in_image_flat)-np.amin(intensity_values_in_image_flat)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_g, I_g_std, I_r, I_r_std, x_loc,y_loc = df_to_array(df_intensities_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting individual trajectories history. \n",
    "\n",
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "selected_timePoint = 0\n",
    "channel = 1\n",
    "plt.imshow(list_videos[0][selected_timePoint,:,:,channel],cmap='Greys_r')\n",
    "#plt.imshow(selected_mask,cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "for i in range(0, x_loc.shape[0]):  # this loop iterated for each trajectory. This is achieved by using the total number of rows in x_loc, using this: ==> \"x_loc.shape[0]\"\n",
    "  plt.plot(x_loc[i,:],y_loc[i,:], '-',linewidth = 0.5 , color = 'r')  # Then we plot the complete trajectory for each particle.\n",
    "  plt.plot(x_loc[i,0],y_loc[i,0], marker='o',markersize = 1 , color = 'y')  # Then we plot the complete trajectory for each particle.\n",
    "\n",
    "contuour_position = find_contours(selected_mask[:, :], 0.8)\n",
    "plt.fill(contuour_position[0][:, 1], contuour_position[0][:, 0], facecolor = 'none', edgecolor = 'yellow') # mask nucleus\n",
    "\n",
    "name_figure = 'trajectories.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "\n",
    "plt.tight_layout() \n",
    "#plt.savefig(figure_directory, transparent=True,dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting individual trajectories history. \n",
    "empty_matrix = np.zeros_like(list_videos[0][selected_timePoint,:,:,channel])\n",
    "empty_matrix = empty_matrix+1\n",
    "\n",
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "selected_timePoint = 0\n",
    "channel = 1\n",
    "plt.imshow(empty_matrix,cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "for i in range(0, x_loc.shape[0]):  # this loop iterated for each trajectory. This is achieved by using the total number of rows in x_loc, using this: ==> \"x_loc.shape[0]\"\n",
    "  plt.plot(x_loc[i,:],y_loc[i,:], '-',linewidth = 0.5 , color = 'r')  # Then we plot the complete trajectory for each particle.\n",
    "  plt.plot(x_loc[i,0],y_loc[i,0], marker='o',markersize = 1 , color = 'y')  # Then we plot the complete trajectory for each particle.\n",
    "\n",
    "contuour_position = find_contours(selected_mask[:, :], 0.8)\n",
    "plt.fill(contuour_position[0][:, 1], contuour_position[0][:, 0], facecolor = 'none', edgecolor = 'yellow') # mask nucleus\n",
    "\n",
    "name_figure = 'simulated_cell.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(figure_directory, transparent=True,dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting individual trajectories history. \n",
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "selected_timePoint = 0\n",
    "channel = 1\n",
    "plt.imshow(list_videos[0][selected_timePoint,:,:,channel],cmap='Greys_r')\n",
    "#plt.imshow(selected_mask,cmap='Greys_r')\n",
    "plt.axis('off')\n",
    "for i in range(0, x_loc.shape[0]):  # this loop iterated for each trajectory. This is achieved by using the total number of rows in x_loc, using this: ==> \"x_loc.shape[0]\"\n",
    "  plt.plot(x_loc[i,:],y_loc[i,:], '-',linewidth = 0.5 , color = 'r')  # Then we plot the complete trajectory for each particle.\n",
    "name_figure = 'trajectories.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.tight_layout() \n",
    "plt.savefig(figure_directory, transparent=True,dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intensity histograms with au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "axes[0].hist(ssa_trajectories_timePoint,bins=60,density=True, stacked=True, color='orangered' )     \n",
    "axes[0].set(title='Simulation')\n",
    "axes[0].set(xlabel='intensities (ump)')\n",
    "axes[0].set(ylabel='count')\n",
    "\n",
    "axes[1].hist(all_cells_green_int,bins=60,density=True, stacked=True, color='chartreuse' )     \n",
    "axes[1].set(title='Tracking')\n",
    "axes[1].set(xlabel='intensities (au)')\n",
    "axes[1].set(ylabel='count')\n",
    "\n",
    "axes[2].hist(intensity_values_in_image_flat,bins=60,density=True, stacked=True, color='cyan' )     \n",
    "axes[2].set(title='Image')\n",
    "axes[2].set(xlabel='intensities (au)')\n",
    "axes[2].set(ylabel='count')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing intensities to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ X_{norm} = \\frac{X -min(X)}{max(X) - min(X)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting normalized intensities\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "axes[0].hist(ssa_trajectories_timePoint_normalized,bins=60,density=True, stacked=True, color='orangered' )     \n",
    "axes[0].set(title='Simulation')\n",
    "axes[0].set(xlabel='intensities (norm)')\n",
    "axes[0].set(ylabel='count')\n",
    "\n",
    "axes[1].hist(all_cells_green_int_normalized,bins=60,density=True, stacked=True, color='chartreuse' )     \n",
    "axes[1].set(title='Tracking')\n",
    "axes[1].set(xlabel='intensities (norm)')\n",
    "axes[1].set(ylabel='count')\n",
    "\n",
    "axes[2].hist(intensity_values_in_image_normalized,bins=60,density=True, stacked=True, color='cyan' )     \n",
    "axes[2].set(title='Image')\n",
    "axes[2].set(xlabel='intensities (au)')\n",
    "axes[2].set(ylabel='count')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cummulative frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "data1 = ssa_trajectories_timePoint_normalized\n",
    "data_sorted_1 = np.sort(data1)\n",
    "p_1 =np.linspace(0, 1, len(data1), endpoint=False)\n",
    "\n",
    "data2 = all_cells_green_int_normalized\n",
    "data_sorted_2 = np.sort(data2)\n",
    "p_2 =np.linspace(0, 1, len(data2), endpoint=False)\n",
    "\n",
    "data3 = intensity_values_in_image_normalized\n",
    "data_sorted_3 = np.sort(data3)\n",
    "p_3 =np.linspace(0, 1, len(data3), endpoint=False)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(data_sorted_1, p_1, 'orangered',linewidth=3,label ='Simulation')\n",
    "plt.plot(data_sorted_2, p_2,'chartreuse',linewidth=3,label ='tracking')\n",
    "plt.plot(data_sorted_3, p_3,'cyan',linewidth=3,label ='Image')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('cumfreq')\n",
    "plt.ylabel('Cumulative probability')\n",
    "plt.xlabel('Normalized intensity')\n",
    "plt.show()\n",
    "\n",
    "# Print number of spots\n",
    "print('Number of spots for Simulation:',len(data1))\n",
    "print('Number of spots recovered from tracking:',len(data2))\n",
    "print('Number of spots recovered from image:',len(data3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison using the KS-distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Kolmogorov distance\n",
    "\n",
    "ks_distance = scipy.stats.kstest(data1,data2).statistic\n",
    "print('The KS-distance between SSA and tracking is:' , round(ks_distance,2))\n",
    "\n",
    "ks_distance = scipy.stats.kstest(data1,data3).statistic\n",
    "print('The KS-distance between SSA and image is:' , round(ks_distance,2))\n",
    "\n",
    "#ks_distance = scipy.stats.kstest(data3,data2).statistic\n",
    "#print('The KS-distance between image and tracking is:' , round(ks_distance,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison using the Anderson-Darling distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_distance,_,_ = scipy.stats.anderson_ksamp([data1,data2],midrank=False)\n",
    "print('The AD-distance between SSA and tracking is:' , round(ad_distance,2))\n",
    "\n",
    "ad_distance,_,_ = scipy.stats.anderson_ksamp([data1,data3],midrank=False)\n",
    "print('The AD-distance between SSA and image is:' , round(ad_distance,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#\n",
    "## Comparison using likelihood function\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LL_fun(real_data,simulation_data,nbins=30):\n",
    "    hist_exp_data, hist_exp_bins = np.histogram( real_data , bins=nbins)\n",
    "    dist_sim_data, dist_sim_bins = np.histogram(simulation_data, bins=hist_exp_bins, density=True)\n",
    "    dist_sim_data[dist_sim_data ==0] = 1e-7\n",
    "    LL_int_distb = np.dot(hist_exp_data,np.log(dist_sim_data))    # likelihood function for comparing distributions\n",
    "    return LL_int_distb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## LOG LIKELIHOOD OF THE INTENSITY DISTRIBUTIONS\n",
    "\n",
    "LL_ssa_tracking = LL_fun(real_data= data_sorted_1,simulation_data=data_sorted_2,nbins=40)\n",
    "print('The Likelihood between SSA and tracking is:' , round(LL_ssa_tracking,2))\n",
    "\n",
    "LL_ssa_img = LL_fun(real_data=data_sorted_1, simulation_data=data_sorted_3,nbins=40)\n",
    "print('The Likelihood between SSA and image is:' , round(LL_ssa_img,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "axs[0].set_title(\"Red\")\n",
    "axs[0].set_xlabel(\"SNR\")\n",
    "axs[0].set_ylabel(\"Frequency\")\n",
    "axs[0].hist(df_intensities_real.SNR_red.values,bins=30)\n",
    "\n",
    "axs[1].set_title(\"Green\")\n",
    "axs[1].set_xlabel(\"SNR\")\n",
    "axs[1].set_ylabel(\"Frequency\")\n",
    "axs[1].hist(df_intensities_real.SNR_green.values,bins=30)\n",
    "try:\n",
    "    axs[2].set_title(\"Blue\")\n",
    "    axs[2].set_xlabel(\"SNR\")\n",
    "    axs[2].set_ylabel(\"Frequency\")\n",
    "    axs[2].hist(df_intensities_real.SNR_blue.values,bins=30)\n",
    "except:\n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

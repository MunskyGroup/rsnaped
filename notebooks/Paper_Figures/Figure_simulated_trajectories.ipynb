{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os; from os import listdir; from os.path import isfile, join\n",
    "import re  \n",
    "#from skimage import io \n",
    "from skimage.io import imread\n",
    "# To manipulate arrays\n",
    "import numpy as np \n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pathlib\n",
    "import sys\n",
    "from skimage.exposure import rescale_intensity\n",
    "import rsnapsim as rss\n",
    "from skimage.measure import find_contours\n",
    "# Plotting\n",
    "import matplotlib as mpl ; import matplotlib.pyplot as plt \n",
    "# To create interactive elements\n",
    "import ipywidgets as widgets ; from ipywidgets import interact, interactive, fixed, interact_manual, Button, HBox, VBox, Layout, GridspecLayout ; from IPython.display import Image\n",
    "\n",
    "import dna_features_viewer\n",
    "from dna_features_viewer import BiopythonTranslator, GraphicFeature, GraphicRecord, CircularGraphicRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Deffining directories\n",
    "current_dir = pathlib.Path().absolute()\n",
    "sequences_dir = current_dir.parents[1].joinpath('DataBases','gene_files')\n",
    "video_dir = current_dir.parents[1].joinpath('DataBases','videos_for_sim_cell')\n",
    "#trajectories_dir = current_dir.parents[1].joinpath('DataBases','rsnapsim_simulations','bactin_ssa.npy')\n",
    "trajectories_dir = current_dir.parents[1].joinpath('DataBases','rsnapsim_simulations','kdm5b_ssa.npy')\n",
    "rsnaped_dir = current_dir.parents[1].joinpath('rsnaped')\n",
    "gene_file = current_dir.parents[1].joinpath('DataBases','gene_files','KDM5B_withTags.txt')\n",
    "masks_dir = current_dir.parents[1].joinpath('DataBases','masks_for_sim_cell')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to dropbox\n",
    "from sys import platform as _platform\n",
    "if _platform == \"linux\" or _platform == \"linux2\":\n",
    "    dropbox_address = pathlib.Path('/','home','luisub','Dropbox', 'Project_rSNAPed','manuscript','Figures','Poster')\n",
    "elif _platform == \"darwin\":\n",
    "    dropbox_address = pathlib.Path('/','Users','luisaguilera','Dropbox', 'Project_rSNAPed','manuscript','Figures','Poster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e293cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir= current_dir.joinpath('Figures')\n",
    "output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Importing rSNAPed\n",
    "sys.path.append(str(rsnaped_dir))\n",
    "import rsnaped as rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dna_features_viewer import BiopythonTranslator\n",
    "class MyCustomTranslator(BiopythonTranslator):\n",
    "    \"\"\"Custom translator\n",
    "    \"\"\"\n",
    "    def compute_feature_color(self, feature):\n",
    "        if feature.type == \"CDS\":\n",
    "            return \"#57B956\"\n",
    "        elif feature.type == \"FLAG\":\n",
    "            return \"#ff0000\"\n",
    "        elif feature.type == \"MS2\":\n",
    "            return \"#098BF5\"\n",
    "        elif feature.type == \"PP7\": \n",
    "            return \"#EB5559\"\n",
    "        else:\n",
    "            return \"#C4B07B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c21af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_files = 'POSTER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plasmid sequences\n",
    "'''\n",
    "gene_file_pUB_SM_KDM5B_PP7 = str(sequences_dir.joinpath('kdm5b.gb')) # plasmid pUB_SM_KDM5B_PP7 \n",
    "\n",
    "graphic_record = MyCustomTranslator().translate_record(gene_file_pUB_SM_KDM5B_PP7) \n",
    "ax, _ = graphic_record.plot(figure_width=20, strand_in_label_threshold=7)\n",
    "#ax.set_title('pUB_SM_KDM5B_PP7 (1895 codons)')\n",
    "graphic_record.plot_legend(ax=ax, loc=1, ncol=3, frameon=False)\n",
    "\n",
    "name_figure = 'sequence.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "\n",
    "ax.figure.savefig(figure_directory)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = (2.5, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters that need to be tested. \n",
    "number_of_simulated_cells = 1 # PLEASE TEST MIN 1 MAX 10\n",
    "number_spots_per_cell = 20     # PLEASE TEST MIN 5 MAX 200\n",
    "simulation_time_in_sec = 1501     # PLEASE TEST MIN 10 MAX 100\n",
    "diffusion_coefficient = 0.5    # PLEASE TEST MIN 0.1 MAX 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "intensity_calculation_method = 'disk_donut'  # options are : 'total_intensity' and 'disk_donut' 'gaussian_fit'\n",
    "mask_selection_method = 'max_area' # options are : 'max_spots' and 'max_area' \n",
    "use_optimization_for_tracking = 1 # 0 not using, 1 is using optimization\n",
    "frame_selection_empty_video = 'linear_interpolation' # Options are: 'constant' , 'shuffle' and 'loop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "particle_size = 5 # spot size for the simulation and tracking.\n",
    "elongation_rate = 10\n",
    "initiation_rate = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_scale_ch0 = 100\n",
    "intensity_scale_ch1 = 400\n",
    "intensity_scale_ch2 = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_detection_size = particle_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsnapsim_ssa(gene_file,ke,ki,frames=300,frame_rate=1,n_traj=20):\n",
    "    '''\n",
    "    This function uses rsnapsim to simulate the single-molecule translation dynamcis of any gene.\n",
    "    Inputs:\n",
    "    gene_file : str, with the location of a fasta file.\n",
    "    ke : float, elongation rate.\n",
    "    ki: float, initiation rate.\n",
    "    frames: int, total number of simulation frames in seconds.\n",
    "    n_traj: int, number of trajectories to simulate\n",
    "    frame_rate : int, frame rate per second\n",
    "    Outputs:\n",
    "    ssa_int : NumPy array with dimenssions [Time_points, simulated_trajectories]\n",
    "    '''\n",
    "    poi_strs, poi_objs, tagged_pois,raw_seq = rss.seqmanip.open_seq_file(str(gene_file))\n",
    "    gene_obj = tagged_pois['1'][0]\n",
    "    gene_obj.ke_mu = ke\n",
    "    rss.solver.protein = gene_obj #pass the protein object\n",
    "    t_burnin = 1000\n",
    "    t = np.linspace(0,t_burnin+frames,(t_burnin+frames+1)*(frame_rate))\n",
    "    number_probes = np.amax(gene_obj.probe_vec)\n",
    "    ints = []\n",
    "    #for i in tq.tqdm(range(n_traj)):\n",
    "    counter = 0\n",
    "    while counter < n_traj:\n",
    "      ssa_solution = rss.solver.solve_ssa(gene_obj.kelong, t, ki=ki, kt = ke, low_memory=True,record_stats=False,n_traj=1)\n",
    "      ssa_int =  ssa_solution.intensity_vec[0,t_burnin*frame_rate:-1,:]\n",
    "      if np.mean(ssa_int)> 1:\n",
    "        ints.append(ssa_int)\n",
    "        counter +=1\n",
    "    ssa = np.array(ints).reshape(n_traj,frames) #flatten the lists back to a numpy array\n",
    "\n",
    "    ssa_ump = ssa/number_probes\n",
    "    return ssa, ssa_ump, gene_obj, t,number_probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_simulated_cells(current_dir, video_dir,masks_dir=None,ke=3,ki=0.03,gene_file =None, trajectories_dir=None, number_of_simulated_cells=3,number_spots_per_cell=80,simulation_time_in_sec =100,step_size_in_sec=1,particle_size=5, diffusion_coefficient =1,path_to_rSNAPsim= None, path_to_save_output='temp',intensity_calculation_method='gaussian_fit',frame_selection_empty_video=frame_selection_empty_video):\n",
    "    spot_size = particle_size\n",
    "    spot_sigma = 1\n",
    "    # Code that creates the folder to store results.\n",
    "    diffusion_coefficient_string = str(diffusion_coefficient).replace('.','_')\n",
    "    directory_name = 'Simulation_V2__'+'ns_'+str(number_spots_per_cell) +'_diff_'+ diffusion_coefficient_string \n",
    "    path_to_save_output = 'temp'\n",
    "    save_to_path =  current_dir.joinpath(path_to_save_output , directory_name )\n",
    "    if not os.path.exists(str(save_to_path)):\n",
    "        os.makedirs(str(save_to_path))\n",
    "    else:\n",
    "        shutil.rmtree(str(save_to_path))\n",
    "        os.makedirs(str(save_to_path))\n",
    "    counter = 0\n",
    "    ## Main loop that creates each cell and dataframe\n",
    "    for cell_number in range (0, number_of_simulated_cells):\n",
    "        output_directory_name = str(video_dir)\n",
    "        list_files_names = sorted([f for f in listdir(output_directory_name) if isfile(join(output_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "        list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "        path_files = [ str(video_dir.joinpath(f).resolve()) for f in list_files_names ] # creating the complete path for each file\n",
    "        \n",
    "        \n",
    "        selected_video = 2 \n",
    "        \n",
    "        video_path = path_files[selected_video]        \n",
    "        video = imread(video_path) \n",
    "\n",
    "        # Reducing in a half the intensity in the original video\n",
    "        video = video//2\n",
    "\n",
    "        empty_videos = video\n",
    "        \n",
    "        # Loading the mask image\n",
    "        if not (masks_dir is None):\n",
    "            mask_image=imread(masks_dir.joinpath('mask_cell_shape_'+str(selected_video)+'.tif'))       \n",
    "        else:\n",
    "            mask_image=None\n",
    "        \n",
    "        counter +=1\n",
    "        if counter>=len(path_files):\n",
    "            counter =0\n",
    "        if not (trajectories_dir is None ):\n",
    "            # Loading trajectories from file\n",
    "            ssa_trajectories = np.load(str(trajectories_dir))\n",
    "            random_index_ch0 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "            random_index_ch1 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "            random_index_ch2 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "            simulated_trajectories_ch0 = ssa_trajectories[random_index_ch0,0:simulation_time_in_sec:step_size_in_sec]\n",
    "            simulated_trajectories_ch1 = ssa_trajectories[random_index_ch1,0:simulation_time_in_sec:step_size_in_sec]\n",
    "            simulated_trajectories_ch2 =  ssa_trajectories[random_index_ch2,0:simulation_time_in_sec:step_size_in_sec]\n",
    "        else:\n",
    "            # Simulations for intensity\n",
    "            ssa1,ssa1_ump,_,_,number_probes = rsnapsim_ssa(gene_file,ke,ki,frames=simulation_time_in_sec,frame_rate=1,n_traj=number_spots_per_cell) # rss.ssa_solver(n_traj = number_spots_per_cell, start_time=starting_time,tf=starting_time+n_frames, tstep=starting_time+n_frames,k_elong_mean=3, k_initiation=.03)  # tstep = total number of steps including the burnin time \n",
    "            simulated_trajectories_ch1 = ssa1_ump\n",
    "            ssa2,ssa2_ump,_,_,number_probes =  rsnapsim_ssa(gene_file,ke,ki,frames=simulation_time_in_sec,frame_rate=1,n_traj=number_spots_per_cell) # rss.ssa_solver(n_traj = number_spots_per_cell, start_time=starting_time,tf=starting_time+n_frames, tstep=starting_time+n_frames,k_elong_mean=3, k_initiation=.03)  # tstep = total number of steps including the burnin time \n",
    "            simulated_trajectories_ch2 = ssa2_ump\n",
    "            simulated_trajectories_ch0 = simulated_trajectories_ch1\n",
    "        #simulated_trajectories_ch0 = None\n",
    "        # Running the cell simulation\n",
    "        saved_file_name = str(save_to_path.joinpath('sim_cell_'+str(cell_number)))\n",
    "        tensor_video , spot_positions_movement, DataFrame_particles_intensities = rsp.SimulatedCell( base_video=video, mask_image=mask_image, number_spots = number_spots_per_cell, number_frames=simulation_time_in_sec, step_size=step_size_in_sec, diffusion_coefficient =diffusion_coefficient, simulated_trajectories_ch0=simulated_trajectories_ch0, size_spot_ch0=spot_size, spot_sigma_ch0=spot_sigma, simulated_trajectories_ch1=simulated_trajectories_ch1, size_spot_ch1=spot_size, spot_sigma_ch1=spot_sigma, simulated_trajectories_ch2=simulated_trajectories_ch2, size_spot_ch2=spot_size, spot_sigma_ch2=spot_sigma, ignore_ch0=0,ignore_ch1=0, ignore_ch2=1,save_as_tif_uint8=0,save_as_tif =1,save_as_gif=0, save_dataframe=1, saved_file_name=saved_file_name,create_temp_folder = False, intensity_calculation_method=intensity_calculation_method,perform_video_augmentation=0,frame_selection_empty_video=frame_selection_empty_video ,intensity_scale_ch0 = intensity_scale_ch0,intensity_scale_ch1 = intensity_scale_ch1,intensity_scale_ch2 = intensity_scale_ch2).make_simulation()      \n",
    "        #print ('The results are saved in folder: ', saved_file_name)\n",
    "    return save_to_path, simulated_trajectories_ch0, simulated_trajectories_ch1, simulated_trajectories_ch2, empty_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the simulation\n",
    "start = timer()\n",
    "output_directory_name, simulated_trajectories_ch0, simulated_trajectories_ch1, simulated_trajectories_ch2, empty_videos = fun_simulated_cells(current_dir,video_dir,masks_dir=masks_dir,ke=elongation_rate, ki=initiation_rate,trajectories_dir=None,gene_file= gene_file, number_of_simulated_cells=number_of_simulated_cells,number_spots_per_cell=number_spots_per_cell,simulation_time_in_sec =simulation_time_in_sec,step_size_in_sec=1,particle_size=particle_size, diffusion_coefficient=diffusion_coefficient,path_to_rSNAPsim= None,intensity_calculation_method=intensity_calculation_method,frame_selection_empty_video=frame_selection_empty_video)\n",
    "end = timer()\n",
    "print('Time to generate simulated data:',round(end - start), ' sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reads the folder with the results and import the simulations as lists\n",
    "list_files_names = sorted([f for f in listdir(output_directory_name) if isfile(join(output_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files = [ str(output_directory_name.joinpath(f).resolve()) for f in list_files_names ] # creating the complete path for each file\n",
    "\n",
    "# Reading the microscopy data\n",
    "list_videos_original = [imread(f)[:,:,:,:] for f in  path_files] # List with all the videos\n",
    "nimg = number_of_simulated_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling images\n",
    "rescale_video = False\n",
    "if rescale_video == True:\n",
    "    list_videos = []\n",
    "    number_channels = list_videos_original[0].shape[-1]\n",
    "    number_z_slices = list_videos_original[0].shape[0]\n",
    "    for i in range (0,nimg ):\n",
    "        temp_img = np.zeros_like(list_videos_original[0])\n",
    "        for j in range(0,number_channels):\n",
    "            temp_img[:,:,:,j] =  np.asarray( [ rescale_intensity(list_videos_original[i][z,:,:,j], in_range='image', out_range='dtype')  for z in range (0, number_z_slices)]  )\n",
    "        list_videos.append(temp_img)\n",
    "else:\n",
    "    list_videos = list_videos_original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_timepoint = 0 #simulation_time_in_sec-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib as mpl\n",
    "label_size = 5\n",
    "mpl.rcParams['xtick.labelsize'] = label_size \n",
    "mpl.rcParams['ytick.labelsize'] = label_size \n",
    "mpl.rcParams['axes.linewidth'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(8,0.7),dpi=300)\n",
    "plt.figure(figsize=(3.8,1.4),dpi=300)\n",
    "\n",
    "selected_trajectory = 0\n",
    "plt.plot(simulated_trajectories_ch1[selected_trajectory,:],color='#0432ff')\n",
    "name_figure = name_files+'_SSA.png'\n",
    "figure_directory = str(output_dir.joinpath(name_figure ) )\n",
    "plt.ylabel('SSA [ump]', fontsize=6)\n",
    "plt.xlabel('time [s]', fontsize=6)\n",
    "plt.xlim((1, 1000))\n",
    "plt.savefig(figure_directory, transparent=False,dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = str(output_directory_name.joinpath('sim_cell_0_df.csv'))\n",
    "df_intensities_real = pd.read_csv(file_name)  \n",
    "intensity_values_in_image_trajectory = df_intensities_real[df_intensities_real['particle'] ==selected_trajectory].green_int_mean.values\n",
    "\n",
    "#plt.figure(figsize=(8,0.7),dpi=300)\n",
    "plt.figure(figsize=(3.8,1.4),dpi=300)\n",
    "\n",
    "plt.plot(intensity_values_in_image_trajectory,color='#0432ff')\n",
    "name_figure = name_files+'_SSA_in_cell.png'\n",
    "figure_directory = str(dropbox_address.joinpath(name_figure ) )\n",
    "plt.ylabel('Intensity [au]', fontsize=12)\n",
    "plt.xlim((1, 1000))\n",
    "plt.xlabel('time [s]', fontsize=12)\n",
    "plt.savefig(figure_directory, transparent=False,dpi=300, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "plt.rcParams['axes.linewidth'] = 1.5\n",
    "plt.rcParams['axes.grid'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_array(dataframe_simulated_cell):\n",
    "    '''\n",
    "    This function takes the dataframe and extracts the information from it. \n",
    "    Information is separated by particles. Notice that dataframe contains information about 600 particles.\n",
    "\n",
    "    Input\n",
    "        dataframe_simulated_cell : pandas dataframe\n",
    "\n",
    "    Returns\n",
    "        I_g : Intensities for each particle in the green channel. NumPy array with dimensions [number_particles, time_points]\n",
    "        I_g_std : Std for the intensities for each particle in the green channel.  NumPy array with dimensions [number_particles, time_points]\n",
    "        I_r : Intensities for each particle in the red channel. NumPy array with dimensions [number_particles, time_points]\n",
    "        I_r_std : Std for the intensities for each particle in the red channel. NumPy array with dimensions [number_particles, time_points]\n",
    "        x_loc : x position for each particle in the dataframe. NumPy array with dimensions [number_particles, time_points]\n",
    "        y_loc : y position for each particle in the dataframe. NumPy array with dimensions [number_particles, time_points]\n",
    "  \n",
    "    '''\n",
    "    # get the total number of particles in all cells\n",
    "    total_particles = 0\n",
    "    for cell in set(dataframe_simulated_cell['cell_number']):\n",
    "        total_particles += len(set(dataframe_simulated_cell[dataframe_simulated_cell['cell_number'] == 0]['particle'] ))\n",
    "\n",
    "    #preallocate numpy array sof n_particles by nframes\n",
    "    I_g = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] )  #intensity green\n",
    "    I_g_std = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] ) #intensity green std\n",
    "    x_loc = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] ) #x loc\n",
    "    y_loc = np.zeros([total_particles, np.max(dataframe_simulated_cell['frame'])+1] ) #y_loc\n",
    "    I_r_std   = np.zeros([total_particles, (np.max(dataframe_simulated_cell['frame'])+1)] ) #intensity red\n",
    "    I_r = np.zeros([total_particles, (np.max(dataframe_simulated_cell['frame'])+1) ] ) #intensity red std\n",
    "    k = 0\n",
    "\n",
    "    # For loops that iterate for each particle and stores the data in the previously pre-alocated arrays.\n",
    "    for cell in set(dataframe_simulated_cell['cell_number']):  #for every cell \n",
    "        for particle in set(dataframe_simulated_cell[dataframe_simulated_cell['cell_number'] == 0]['particle'] ): #for every particle\n",
    "            tmpdf = dataframe_simulated_cell[(dataframe_simulated_cell['cell_number'] == cell) & (dataframe_simulated_cell['particle'] == particle)]  #slice the dataframe\n",
    "            maxframe = np.max(tmpdf['frame'])\n",
    "            minframe = np.min(tmpdf['frame'])\n",
    "            I_g[k, 0:(maxframe+1-minframe)] = tmpdf['green_int_mean']  #fill the arrays to return out\n",
    "            x_loc[k, 0:(maxframe+1-minframe)] = tmpdf['x']\n",
    "            y_loc[k, 0:(maxframe+1-minframe)] = tmpdf['y']\n",
    "            #I_g_std[k, 0:(maxframe+1-minframe)] = tmpdf['green_int_std']\n",
    "            I_r[k, 0:(maxframe+1-minframe)] = tmpdf['red_int_mean']\n",
    "            #I_r_std[k, 0:(maxframe+1-minframe)] = tmpdf['red_int_std']\n",
    "            k+=1 #iterate over k (total particles)\n",
    "    #return I_g, I_g_std, I_r, I_r_std, x_loc,y_loc   #return everything backout\n",
    "    return I_g, I_r, x_loc,y_loc   #return everything backout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the folder with the results and import the simulations as lists\n",
    "list_files_names = sorted([f for f in listdir(output_directory_name) if isfile(join(output_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files = [ str(output_directory_name.joinpath(f).resolve()) for f in list_files_names ] # creating the complete path for each file\n",
    "\n",
    "# Reading the microscopy data\n",
    "list_videos_original = [imread(f)[:,:,:,:] for f in  path_files] # List with all the videos\n",
    "nimg = number_of_simulated_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the dataframes\n",
    "list_files_dfnames = sorted([f for f in listdir(output_directory_name) if isfile(join(output_directory_name, f)) and ('.csv') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_dfnames.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files_df = [ str(output_directory_name.joinpath(f).resolve()) for f in list_files_dfnames ] # creating the complete path for each file\n",
    "list_df_real_positions = [pd.read_csv(f) for f in  path_files_df] # List with all the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_g, I_r, x_loc,y_loc = df_to_array(df_intensities_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = (2.5,2.5)\n",
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "selected_timePoint = 0\n",
    "channel = 1\n",
    "plt.imshow(list_videos[0][selected_timePoint,:,:,channel],cmap='Greys')\n",
    "plt.axis('off')\n",
    "#plt.title('Simulated cell' , size=16)\n",
    "#plt.ylabel('count', size=16)\n",
    "#plt.xlabel('SNR', size=16)\n",
    "name_figure = name_files+'_simulated_cell_for_crops.png'\n",
    "figure_directory = str(output_dir.joinpath(name_figure ) )\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.savefig(figure_directory, transparent=True,dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncrops = 30\n",
    "\n",
    "time_vector = np.round(np.linspace(0,simulation_time_in_sec-1,ncrops)).astype(int)\n",
    "time_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plotting\n",
    "\n",
    "channel = 0\n",
    "\n",
    "#fig, axes = plt.subplots(nrows=1, ncols=ncrops, figsize=(7, 2))\n",
    "fig, axes = plt.subplots(nrows=1, ncols=ncrops, figsize=(3.8, 0.5))\n",
    "\n",
    "disk_size = 5\n",
    "\n",
    "max_val=[]\n",
    "min_val=[]\n",
    "\n",
    "for i in range(0, ncrops):\n",
    "    y_pos = y_loc[0, time_vector[i]].astype(int)\n",
    "    x_pos = x_loc[0,time_vector[i] ].astype(int)\n",
    "    crop_img= list_videos[0][time_vector[i], y_pos-(disk_size): y_pos+(disk_size+1) , x_pos-(disk_size):x_pos+(disk_size+1),  channel ] \n",
    "    max_val.append(np.amax(crop_img))\n",
    "    min_val.append(np.amin(crop_img))\n",
    "\n",
    "\n",
    "for i in range(0, ncrops):\n",
    "    y_pos = y_loc[0, time_vector[i]].astype(int)\n",
    "    x_pos = x_loc[0,time_vector[i] ].astype(int)\n",
    "    crop_img= list_videos[0][time_vector[i], y_pos-(disk_size): y_pos+(disk_size+1) , x_pos-(disk_size):x_pos+(disk_size+1),  channel ] \n",
    "\n",
    "    axes[i].imshow(crop_img,cmap='Greys', vmin=min(min_val), vmax=max(max_val))\n",
    "    axes[i].axis('off')\n",
    "\n",
    "#axes[2].hist(SNR_b_flat,bins=60,density=True, stacked=True, color='cyan' )     \n",
    "#axes[2].set(title='Image')\n",
    "#axes[2].set(xlabel='intensities (au)')\n",
    "#axes[2].set(ylabel='count')\n",
    "name_figure = name_files+'_crops.png'\n",
    "figure_directory = str(output_dir.joinpath(name_figure ) )\n",
    "\n",
    "plt.tight_layout() \n",
    "plt.subplots_adjust(wspace=0.1, hspace=0)\n",
    "plt.savefig(figure_directory, transparent=True,dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879fdd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = plt.figure(figsize=(2, 1.8), dpi=300)\n",
    "fig = plt.figure(figsize=(3.8, 2.2), dpi=300)\n",
    "\n",
    "plt.hist(I_g[:, -1], bins=20, density=False, stacked=True, color='#0432ff')\n",
    "# plt.title('Simulation')\n",
    "plt.xlabel('intensity')\n",
    "plt.ylabel('count')\n",
    "plt.tight_layout()\n",
    "\n",
    "name_figure = name_files+'_Hist.png'\n",
    "figure_directory = str(output_dir.joinpath(name_figure))\n",
    "plt.savefig(figure_directory, transparent=True, dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d70e490",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_autocorrelation(data, g0='G0', norm='individual'):\n",
    "    n_traj = data.shape[0]\n",
    "    acf_vec = np.zeros(data.shape)\n",
    "\n",
    "    def get_acc_fft(signal):\n",
    "        N = len(signal)\n",
    "        fvi = np.fft.fft(signal, n=2*N)\n",
    "        acf = fvi*np.conjugate(fvi)\n",
    "        acf = np.fft.ifft(acf)\n",
    "        acf = np.real(acf[:N])/float(N)\n",
    "        return acf\n",
    "\n",
    "    global_mean = np.mean(data)\n",
    "    global_var = np.var(data)\n",
    "    for i in range(n_traj):\n",
    "        if norm == 'individual':\n",
    "            if np.mean(data[i] == 0):\n",
    "                signal = (data[i] - 1e-6) / 1e-6\n",
    "            else:\n",
    "                signal = (data[i] - np.mean(data[i])) / np.var(data[i])\n",
    "        else:\n",
    "            signal = (data[i] - global_mean) / global_var\n",
    "        if g0 == 'G1':\n",
    "            g1 = get_acc_fft(signal)[1]\n",
    "            acf_vec[i] = get_acc_fft(signal)/g1\n",
    "        if g0 == 'G0':\n",
    "            g = get_acc_fft(signal)[0]\n",
    "            acf_vec[i] = get_acc_fft(signal)/g\n",
    "    return acf_vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f74c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(I_g.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8271e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the auto-correlation function.\n",
    "#acf_from_data = get_autocorrelation(I_g, g0='G0', norm='individual')\n",
    "acf_from_data = get_autocorrelation(I_g, g0='G0', norm='')\n",
    "mean_acf = np.mean(acf_from_data, axis=0)\n",
    "err_acf = np.std(acf_from_data, axis=0) #  /np.sqrt(I_g.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d346b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the ACF and its mean.\n",
    "plt.figure(figsize=(3.8, 2.2))\n",
    "tau = np.arange(0, len(mean_acf), 1)\n",
    "# plt.plot(acf_from_data.T,'green',alpha=.08)\n",
    "plt.plot(tau, mean_acf, '-', linewidth=1.5, color='#0432ff', label='mean ACF')\n",
    "plt.fill_between(tau, mean_acf - err_acf, mean_acf + err_acf, color='k', alpha=0.1)\n",
    "plt.xlim((1, 1000))\n",
    "plt.xlabel('tau')\n",
    "plt.ylabel(r'G/G(0)')\n",
    "plt.legend()\n",
    "#plt.title('ACF for experimental data', color ='red')\n",
    "\n",
    "name_figure = name_files+'_ACF.png'\n",
    "figure_directory = str(output_dir.joinpath(name_figure))\n",
    "plt.savefig(figure_directory, transparent=True, dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df549ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = (3.8, 2.2)\n",
    "label_size = 12\n",
    "plt.figure(figsize=fig_size,dpi=300)\n",
    "plt.plot(I_g[0:20,:].T,'k',alpha=.04)\n",
    "#plt.plot(np.mean(I_g.T,axis=1), linewidth =3,color='#0432ff')\n",
    "plt.plot(I_g.T[:,0], linewidth =1,color='#0432ff')\n",
    "plt.xlabel('time [s]', size=label_size)\n",
    "plt.ylabel('Intensity [au]', size=label_size)\n",
    "plt.xlim((-1,1000))\n",
    "#plt.legend( )\n",
    "name_figure = name_files+'_image_trj.png'\n",
    "figure_directory = str(output_dir.joinpath(name_figure ) )\n",
    "plt.savefig(figure_directory, transparent=True,dpi=300, bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('rsnaped_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "daf7c258a197027f92a823c5e9002157216e53cdde30f9077602d149eebf1043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "greenhouse-blocking",
   "metadata": {},
   "source": [
    "# Integrated Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "universal-abortion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; from os import listdir; from os.path import isfile, join\n",
    "import re  \n",
    "from skimage import io \n",
    "from skimage.io import imread\n",
    "\n",
    "import pkg_resources\n",
    "pkg_resources.require(\"numpy>=`1.20.1\")  #  to use specific numpy version\n",
    "import numpy as np\n",
    "\n",
    "cwd = os.getcwd(); os.chdir('../../rsnaped');import rsnaped as rsp; os.chdir(cwd)\n",
    "from tqdm.notebook import tqdm\n",
    "# To manipulate arrays\n",
    "import random\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import itertools\n",
    "\n",
    "# Plotting\n",
    "import matplotlib as mpl ; import matplotlib.pyplot as plt \n",
    "# To create interactive elements\n",
    "import ipywidgets as widgets ; from ipywidgets import interact, interactive, fixed, interact_manual, Button, HBox, VBox, Layout, GridspecLayout ; from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "manufactured-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters that need to be tested. \n",
    "number_of_simulated_cells = 100  \n",
    "number_spots_per_cell = 42      \n",
    "simulation_time_in_sec = 30     \n",
    "diffusion_coefficient = 0.7      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "african-violence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_timepoint = 0#simulation_time_in_sec-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ranging-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_selection_method = 'max_area' # options are : 'max_spots' and 'max_area' \n",
    "particle_size = 5 # spot size for the simulation and tracking.\n",
    "number_repetitions = 4\n",
    "use_optimization_for_tracking =1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-matrix",
   "metadata": {},
   "source": [
    "## Running the simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "north-reception",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def fun_simulated_cells(number_of_simulated_cells=3,number_spots_per_cell=80,simulation_time_in_sec =100,step_size_in_sec=1,particle_size=5, diffusion_coefficient =1,path_to_rSNAPsim= None, path_to_save_output='./temp',intensity_calculation_method='gaussian_fit'):\n",
    "    spot_size = particle_size\n",
    "    spot_sigma = 2\n",
    "\n",
    "    # Code that creates the folder to store results.\n",
    "    diffusion_coefficient_string = str(diffusion_coefficient).replace('.','_')\n",
    "    directory_name = '/Simulation_V2__'+'ns_'+str(number_spots_per_cell) +'_diff_'+ diffusion_coefficient_string \n",
    "    path_to_save_output = './temp'\n",
    "    save_to_path =  path_to_save_output + directory_name \n",
    "    \n",
    "    if not os.path.exists(save_to_path):\n",
    "        os.makedirs(save_to_path)\n",
    "    else:\n",
    "        shutil.rmtree(save_to_path)\n",
    "        os.makedirs(save_to_path)\n",
    "    \n",
    "    # Loading trajectories from file\n",
    "    ssa_trajectories = np.load('../../DataBases/rsnapsim_simulations/bactin_ssa.npy')\n",
    "    \n",
    "    counter = 0\n",
    "    ## Main loop that creates each cell and dataframe\n",
    "    for cell_number in range (0, number_of_simulated_cells):\n",
    "        ouput_directory_name = '../../DataBases/videos_for_sim_cell'\n",
    "        list_files_names = sorted([f for f in listdir(ouput_directory_name) if isfile(join(ouput_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "        list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "        path_files = [ ouput_directory_name+'/'+f for f in list_files_names ] # creating the complete path for each file\n",
    "        video_path = path_files[counter]        \n",
    "        video = io.imread(video_path) \n",
    "        # Normalization to remove extreme values.\n",
    "        #mean_int_video = np.mean(video[0,:,:,1])\n",
    "        #video = rsp.RemoveExtrema (video, min_percentile=0, max_percentile=99.5,ignore_channel =2).remove_outliers()\n",
    "        \n",
    "        # Scale video intensity \n",
    "        #if mean_int_video < 3000:\n",
    "        #    scale_percentage_value =0.8\n",
    "        #else:\n",
    "        #    scale_percentage_value =0.5\n",
    "        #video = rsp.ScaleIntensity( video, scale_percentage=scale_percentage_value).apply_scale()\n",
    "        counter +=1\n",
    "        if counter>=len(path_files):\n",
    "            counter =0\n",
    "        random_index_ch1 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "        random_index_ch2 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "        simulated_trajectories_ch1 = ssa_trajectories[random_index_ch1,0:simulation_time_in_sec:step_size_in_sec]\n",
    "        simulated_trajectories_ch2 =  ssa_trajectories[random_index_ch2,0:simulation_time_in_sec:step_size_in_sec]\n",
    "        saved_file_name = save_to_path+'/sim_cell_'+str(cell_number)\n",
    "        tensor_video , tensor_for_image_j , spot_positions_movement, tensor_mean_intensity_in_figure, tensor_std_intensity_in_figure, DataFrame_particles_intensities = rsp.SimulatedCell( base_video=video, number_spots = number_spots_per_cell, number_frames=simulation_time_in_sec, step_size=step_size_in_sec, diffusion_coefficient =diffusion_coefficient, simulated_trajectories_ch0=None, size_spot_ch0=spot_size, spot_sigma_ch0=spot_sigma, simulated_trajectories_ch1=simulated_trajectories_ch1, size_spot_ch1=spot_size, spot_sigma_ch1=spot_sigma, simulated_trajectories_ch2=simulated_trajectories_ch2, size_spot_ch2=spot_size, spot_sigma_ch2=spot_sigma, ignore_ch0=0,ignore_ch1=0, ignore_ch2=1,save_as_tif_uint8=0,save_as_tif =1,save_as_gif=0, save_dataframe=1, saved_file_name=saved_file_name,create_temp_folder = False, intensity_calculation_method=intensity_calculation_method).make_simulation()      \n",
    "        print ('The results are saved in folder: ', saved_file_name)\n",
    "    return save_to_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "partial-short",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def remove_extrema(vector,min_percentile = 0 ,max_percentile = 100):\n",
    "    '''This function is intended to remove extrema data given by the min and max percentiles specified by the user'''\n",
    "    vector = vector [vector>0]\n",
    "    max_val = np.percentile(vector, max_percentile)\n",
    "    min_val =  np.percentile(vector, min_percentile)\n",
    "    print(round(min_val,2),round(max_val,2))\n",
    "    new_vector = vector [vector< max_val] # = np.percentile(vector,max_percentile)\n",
    "    new_vector = new_vector [new_vector> min_val] # = np.percentile(vector, min_percentile)\n",
    "    return new_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "improved-wilson",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def test(number_of_simulated_cells,number_spots_per_cell,simulation_time_in_sec ,step_size_in_sec,particle_size, diffusion_coefficient,path_to_rSNAPsim,intensity_calculation_method,use_optimization_for_tracking):\n",
    "    # running the simulation\n",
    "    ouput_directory_name = fun_simulated_cells(number_of_simulated_cells=number_of_simulated_cells,number_spots_per_cell=number_spots_per_cell,simulation_time_in_sec =simulation_time_in_sec,step_size_in_sec=1,particle_size=particle_size, diffusion_coefficient=diffusion_coefficient,path_to_rSNAPsim= None,intensity_calculation_method=intensity_calculation_method)\n",
    "    path = ouput_directory_name\n",
    "    # Reads the folder with the results and import the simulations as lists\n",
    "    list_files_names = sorted([f for f in listdir(ouput_directory_name) if isfile(join(ouput_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "    list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "    path_files = [ ouput_directory_name+'/'+f for f in list_files_names ] # creating the complete path for each file\n",
    "    # Reading the microscopy data\n",
    "    list_videos = [imread(f)[:,:,:,:] for f in  path_files] # List with all the videos\n",
    "    nimg = number_of_simulated_cells\n",
    "    # Tracking\n",
    "    list_DataFrame_particles_intensities= []\n",
    "    list_array_intensities = []\n",
    "    list_time_vector = []\n",
    "    for i in tqdm(range(0,nimg)): \n",
    "        DataFrame_particles_intensities, array_intensities, time_vector, mean_intensities,std_intensities, mean_intensities_normalized, std_intensities_normalized = rsp.PipelineTracking(list_videos[i],particle_size=particle_size,file_name=list_files_names[i],selected_channel=0,intensity_calculation_method =intensity_calculation_method, mask_selection_method = mask_selection_method,show_plot=0, use_optimization_for_tracking =use_optimization_for_tracking).run()    \n",
    "        list_DataFrame_particles_intensities.append(DataFrame_particles_intensities)\n",
    "        list_array_intensities.append(array_intensities)\n",
    "        list_time_vector.append(time_vector)\n",
    "    # Intensity from trajectories\n",
    "    ssa_trajectories = np.load('../../DataBases/rsnapsim_simulations/bactin_ssa.npy')\n",
    "    ssa_trajectories_timePoint = ssa_trajectories[:,sel_timepoint].flatten()\n",
    "    ssa_trajectories_timePoint= remove_extrema(ssa_trajectories_timePoint)\n",
    "    ssa_trajectories_timePoint_normalized = (ssa_trajectories_timePoint-np.amin(ssa_trajectories_timePoint))/ (np.amax(ssa_trajectories_timePoint)-np.amin(ssa_trajectories_timePoint))\n",
    "    # Intensity from tracking\n",
    "    intensity_values_tracking_flat =[]\n",
    "    for i in range(0,nimg):\n",
    "        df_intensities_real = list_DataFrame_particles_intensities[i]  \n",
    "        max_nspots = df_intensities_real['particle'].nunique()\n",
    "        intensity_values_tracking = np.zeros((max_nspots)) # prealocating memory\n",
    "        for j in range (0,max_nspots):\n",
    "            intensity_values_tracking[j] = df_intensities_real[df_intensities_real['particle'] ==j].green_int_mean.values[sel_timepoint]         \n",
    "        intensity_values_tracking_flat.append(intensity_values_tracking.tolist())\n",
    "    merged = list(itertools.chain(*intensity_values_tracking_flat))\n",
    "    merged = [num if num else 0 for num in merged] # removing zeros\n",
    "    merged = np.asarray(merged)\n",
    "    merged= remove_extrema(merged)\n",
    "    intensity_values_tracking_normalized = (merged-np.amin(merged))/ (np.amax(merged)-np.amin(merged)).flatten()\n",
    "    # Extracting the number of real simulations from folder name\n",
    "    ind_str_start = path.find('_ns_') +4\n",
    "    ind_str_end = path.find('_diff') \n",
    "    max_nspots = int(path[ind_str_start:ind_str_end])\n",
    "    intensity_values_in_image = np.zeros((nimg,max_nspots)) # prealocating memory\n",
    "    for i in range(0,nimg):\n",
    "        for j in range (0,max_nspots):\n",
    "            file_name = path+'/sim_cell_'+str(i)+'_df.csv'\n",
    "            df_intensities_real = pd.read_csv(file_name)  \n",
    "            intensity_values_in_image[i,j] = df_intensities_real[df_intensities_real['particle'] ==j].green_int_mean.values[sel_timepoint]         \n",
    "    intensity_values_in_image_flat = intensity_values_in_image.flatten()\n",
    "    intensity_values_in_image_flat =  intensity_values_in_image_flat[intensity_values_in_image_flat>0]\n",
    "    intensity_values_in_image_flat= remove_extrema(intensity_values_in_image_flat)\n",
    "    intensity_values_in_image_normalized = (intensity_values_in_image_flat-np.amin(intensity_values_in_image_flat))/ (np.amax(intensity_values_in_image_flat)-np.amin(intensity_values_in_image_flat)).flatten()\n",
    "    # Data flatten\n",
    "    data1 = ssa_trajectories_timePoint_normalized\n",
    "    data_sorted_1 = np.sort(data1)\n",
    "    data2 = intensity_values_tracking_normalized\n",
    "    data_sorted_2 = np.sort(data2)\n",
    "    data3 = intensity_values_in_image_normalized\n",
    "    data_sorted_3 = np.sort(data3)\n",
    "    # Calculating Kolmogorov distance\n",
    "    ks_distance_tracking = scipy.stats.kstest(data1,data2).statistic\n",
    "    ks_distance_image = scipy.stats.kstest(data1,data3).statistic\n",
    "    return ks_distance_tracking, ks_distance_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "listed-florist",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "intensity_calculation_method = 'total_intensity'  # options are : 'total_intensity' and 'disk_donut' 'gaussian_fit'\n",
    "ks_distance_tracking = np.zeros((number_repetitions))\n",
    "ks_distance_image = np.zeros((number_repetitions))\n",
    "for i in range (0,number_repetitions):\n",
    "    ks_distance_tracking[i], ks_distance_image[i] = test(number_of_simulated_cells=number_of_simulated_cells,number_spots_per_cell=number_spots_per_cell,simulation_time_in_sec =simulation_time_in_sec,step_size_in_sec=1,particle_size=particle_size, diffusion_coefficient=diffusion_coefficient,path_to_rSNAPsim= None,intensity_calculation_method=intensity_calculation_method,use_optimization_for_tracking=use_optimization_for_tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial-district",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KS-distance between SSA and tracking is: [0.15 0.15 0.14 0.14]\n",
      "The KS-distance between SSA and image is: [0.22 0.23 0.2  0.21]\n"
     ]
    }
   ],
   "source": [
    "# total_intensity\n",
    "print('The KS-distance between SSA and tracking is:' , ks_distance_tracking.round(2))\n",
    "print('The KS-distance between SSA and image is:' , ks_distance_image.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "complicated-newport",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "intensity_calculation_method = 'disk_donut'  # options are : 'total_intensity' and 'disk_donut' 'gaussian_fit'\n",
    "ks_distance_tracking = np.zeros((number_repetitions))\n",
    "ks_distance_image = np.zeros((number_repetitions))\n",
    "for i in range (0,number_repetitions):\n",
    "    ks_distance_tracking[i], ks_distance_image[i] = test(number_of_simulated_cells=number_of_simulated_cells,number_spots_per_cell=number_spots_per_cell,simulation_time_in_sec =simulation_time_in_sec,step_size_in_sec=1,particle_size=particle_size, diffusion_coefficient=diffusion_coefficient,path_to_rSNAPsim= None,intensity_calculation_method=intensity_calculation_method,use_optimization_for_tracking=use_optimization_for_tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "infinite-conversation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KS-distance between SSA and tracking is: [0.27 0.27 0.3  0.28]\n",
      "The KS-distance between SSA and image is: [0.06 0.07 0.13 0.07]\n"
     ]
    }
   ],
   "source": [
    "# d&d\n",
    "print('The KS-distance between SSA and tracking is:' , ks_distance_tracking.round(2))\n",
    "print('The KS-distance between SSA and image is:' , ks_distance_image.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "proud-pitch",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "intensity_calculation_method = 'gaussian_fit'  # options are : 'total_intensity' and 'disk_donut' 'gaussian_fit'\n",
    "ks_distance_tracking = np.zeros((number_repetitions))\n",
    "ks_distance_image = np.zeros((number_repetitions))\n",
    "for i in range (0,number_repetitions):\n",
    "    ks_distance_tracking[i], ks_distance_image[i] = test(number_of_simulated_cells=number_of_simulated_cells,number_spots_per_cell=number_spots_per_cell,simulation_time_in_sec =simulation_time_in_sec,step_size_in_sec=1,particle_size=particle_size, diffusion_coefficient=diffusion_coefficient,path_to_rSNAPsim= None,intensity_calculation_method=intensity_calculation_method,use_optimization_for_tracking=use_optimization_for_tracking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "extra-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The KS-distance between SSA and tracking is: [0.14 0.14 0.13 0.11]\n",
      "The KS-distance between SSA and image is: [0.2  0.24 0.21 0.23]\n"
     ]
    }
   ],
   "source": [
    "# gaussian\n",
    "print('The KS-distance between SSA and tracking is:' , ks_distance_tracking.round(2))\n",
    "print('The KS-distance between SSA and image is:' , ks_distance_image.round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single molecule - Manual Pipeline\n",
    "\n",
    "____\n",
    "This code is intended to take a video (.tiff) from fluorescence microscopy, segment the cell,detect single-RNA spots, track the single-RNA spots in time, and quantify spot intensity.\n",
    "____\n",
    "The code is divided in the following sections:\n",
    "\n",
    "* Alignment images taken from the two cameras.\n",
    "* Load microscope video.\n",
    "* Mask selection. Manual selection of a Region Of Interest (ROI).\n",
    "* Particle tracking using trackpy. \n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries and images\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import numpy as np \n",
    "import pathlib\n",
    "import sys\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import trackpy as tp\n",
    "import ipywidgets as widgets                       # Library to plot widgets\n",
    "from ipywidgets import interact, interactive, HBox, Layout, VBox #  importing modules and functions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining directories\n",
    "current_dir = pathlib.Path().absolute()\n",
    "video_dir = current_dir.parents[1].joinpath('DataBases','test_videos','ran_short','MAX_Cell01.tif')\n",
    "beads_dir = current_dir.parents[1].joinpath('DataBases','test_videos','ran_short_beads','Beads01.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing rSNAPed\n",
    "rsnaped_dir = current_dir.parents[1].joinpath('rsnaped')\n",
    "sys.path.append(str(rsnaped_dir))\n",
    "import rsnaped as rsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading images\n",
    "image_with_beads = imread(beads_dir)\n",
    "video = imread(video_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video registration\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing images with beads\n",
    "print('The dimensions in the image with beads are: ', image_with_beads.shape, '\\n')\n",
    "# Visualizing the beads\n",
    "fig, ax = plt.subplots(2,2, figsize=(10, 10))\n",
    "ax[0,0].imshow(image_with_beads[0,:,:],cmap=plt.cm.Reds_r)\n",
    "ax[0,0].set_xticks([]); ax[0,0].set_yticks([])\n",
    "ax[0,1].hist(image_with_beads[0,:,:].flatten(), bins=80,color='red', ec=\"cyan\")\n",
    "ax[0,1].set_xlabel('Intensity'); ax[0,1].set_ylabel('Count')\n",
    "ax[1,0].imshow(image_with_beads[1,:,:],cmap=plt.cm.Greens_r)\n",
    "ax[1,0].set_xticks([]); ax[1,0].set_yticks([])\n",
    "ax[1,1].hist(image_with_beads[1,:,:].flatten(), bins=80,color='green', ec=\"cyan\")\n",
    "ax[1,1].set_xlabel('Intensity'); ax[1,1].set_ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the homography matrix\n",
    "homography_matrix = rsp.BeadsAlignment(first_image_beads= image_with_beads[0,:,:] ,second_image_beads = image_with_beads[1,:,:], spot_size = 5, min_intensity = 300).make_beads_alignment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading images with the cells\n",
    "print('The dimensions in the video are: ', video.shape, '\\n')\n",
    "# Plotting the beads\n",
    "selected_time_point = 0\n",
    "fig, ax = plt.subplots(3,2, figsize=(10, 10))\n",
    "ax[0,0].imshow(video[selected_time_point,:,:,0],cmap=plt.cm.Reds_r)\n",
    "ax[0,0].set_title('Channel 0 = RNA');ax[0,0].set_xticks([]); ax[0,0].set_yticks([])\n",
    "ax[0,1].hist(video[selected_time_point,:,:,0].flatten(), bins=80,color='red', ec=\"cyan\")\n",
    "ax[0,1].set_xlabel('Intensity'); ax[0,1].set_ylabel('Count')\n",
    "ax[1,0].imshow(video[selected_time_point,:,:,1],cmap=plt.cm.Greens_r)\n",
    "ax[1,0].set_title('Channel 1 = Protein 1'); ax[1,0].set_xticks([]); ax[1,0].set_yticks([])\n",
    "ax[1,1].hist(video[selected_time_point,:,:,1].flatten(), bins=80,color='green', ec=\"cyan\")\n",
    "ax[1,1].set_xlabel('Intensity'); ax[1,1].set_ylabel('Count')\n",
    "ax[2,0].imshow(video[selected_time_point,:,:,2],cmap=plt.cm.Blues_r)\n",
    "ax[2,0].set_title('Channel 2 = Protein 2'); ax[2,0].set_xticks([]); ax[2,0].set_yticks([])\n",
    "ax[2,1].hist(video[selected_time_point,:,:,2].flatten(), bins=80,color='blue', ec=\"cyan\")\n",
    "ax[2,1].set_xlabel('Intensity'); ax[2,1].set_ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the alignment transformation to the whole video. Matrix multiplication to align the images from the two cameras.\n",
    "transformed_video = rsp.CamerasAlignment(video, homography_matrix, target_channels= [1,2]).make_video_alignment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the beads\n",
    "selected_time_point = 0\n",
    "fig, ax = plt.subplots(3,2, figsize=(10, 10))\n",
    "ax[0,0].imshow(transformed_video[selected_time_point,:,:,0],cmap=plt.cm.Reds_r)\n",
    "ax[0,0].set_title('Channel 0 = RNA');ax[0,0].set_xticks([]); ax[0,0].set_yticks([])\n",
    "ax[0,1].hist(transformed_video[selected_time_point,:,:,0].flatten(), bins=80,color='red', ec=\"cyan\")\n",
    "ax[0,1].set_xlabel('Intensity'); ax[0,1].set_ylabel('Count')\n",
    "ax[1,0].imshow(transformed_video[selected_time_point,:,:,1],cmap=plt.cm.Greens_r)\n",
    "ax[1,0].set_title('Channel 1 = Protein 1'); ax[1,0].set_xticks([]); ax[1,0].set_yticks([])\n",
    "ax[1,1].hist(transformed_video[selected_time_point,:,:,1].flatten(), bins=80,color='green', ec=\"cyan\")\n",
    "ax[1,1].set_xlabel('Intensity'); ax[1,1].set_ylabel('Count')\n",
    "ax[2,0].imshow(transformed_video[selected_time_point,:,:,2],cmap=plt.cm.Blues_r)\n",
    "ax[2,0].set_title('Channel 2 = Protein 2'); ax[2,0].set_xticks([]); ax[2,0].set_yticks([])\n",
    "ax[2,1].hist(transformed_video[selected_time_point,:,:,2].flatten(), bins=80,color='blue', ec=\"cyan\")\n",
    "ax[2,1].set_xlabel('Intensity'); ax[2,1].set_ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting a region of interest (a.k.a. Mask) in the image\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Magic function to interact with the figure.\n",
    "%matplotlib widget \n",
    "###########\n",
    "# Selecting the first time point and first channel\n",
    "on1= rsp.ManualMask(video=transformed_video,time_point_selected=0,selected_channel=1)  # NOTICE THAT FOR THE MASK SELECTION WE USE THE CHANNEL 1 (GREEN CHANNEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########\n",
    "# Magic function to have the figure as an output in the notebook\n",
    "%matplotlib inline \n",
    "###########\n",
    "arr = np.array([on1.selected_points],'int')\n",
    "mask = cv2.fillPoly(np.zeros(video[0,:,:,1].shape,np.uint8),arr,[1,1,1])\n",
    "plt.figure( figsize=(5, 5))\n",
    "plt.imshow(mask)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle tracking using Trackpy\n",
    "\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The particle tracking is performed using [trackpy](http://http://soft-matter.github.io/trackpy/v0.5.0/)\n",
    "The library documentation can be accessed in the following [link](https://buildmedia.readthedocs.org/media/pdf/trackpy/v0.2.3/trackpy.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the intensity of the detected particles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section generates an histogram with the intensity of the detected particles in the video.\n",
    "particle_size = 7 # according to the documentation must be an odd number 3,5,7,9 etc.\n",
    "minimal_intensity_for_selection = 0 # minimal intensity to detect a particle.\n",
    "selected_channel_for_tracking = 0\n",
    "\n",
    "# \"f\" is a pandas data frame that contains the information about the detected spots\n",
    "f = tp.locate(transformed_video[0,:,:,selected_channel_for_tracking], particle_size, minmass=minimal_intensity_for_selection) \n",
    "print('All particles of size: ',  str(particle_size))\n",
    "plt.figure( figsize=(5,5))\n",
    "tp.annotate(f,transformed_video[0,:,:,selected_channel_for_tracking],color='yellow',plot_style={'markersize': 1})\n",
    "plt.show()\n",
    "\n",
    "print('Intensity distribution for all particles of size: ',  str(particle_size))\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "ax.hist(f['mass'], bins=100, color = \"orangered\", ec=\"cyan\")\n",
    "ax.set(xlabel=\"Particle's 'mass' \", ylabel='count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select an intensity threshold value and particle size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following widget, the user is asked to manually input the particle size and the Intensity threshold, these numbers will be used for during the rest of the code to calculate intensities. Notice that tracking is only performed on channel 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start visualization move the time slider.\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5) # if movie is too big, change size to (7,7)\n",
    "def figure_viewer_tr(time,mass_text, particle_size):\n",
    "    ch = 0  \n",
    "    f = tp.locate(transformed_video[time,:,:,ch],particle_size, minmass=mass_text, maxsize=7, percentile=60) # \"f\" is a pandas data frame that contains the information about the detected spots\n",
    "    tp.annotate(f,transformed_video[time,:,:,ch]) # tp.annotate is a trackpy function that displays the image with the detected spots  \n",
    "values_size=[3,5,7,9] # Notice value must be an odd number.\n",
    "interactive_plot_tr = interactive(figure_viewer_tr, mass_text = widgets.IntSlider(value=400,min=100,max=2000,description='min Intensity'), particle_size = widgets.IntSlider(min=3,max=11,step=2,value=7,description='Particle Size'), time = widgets.IntSlider(min=0,max=video.shape[0]-1,step=1,value=0,description='Time'))\n",
    "controls = HBox(interactive_plot_tr.children[:-1], layout = Layout(flex_flow='row wrap'))\n",
    "output = interactive_plot_tr.children[-1]\n",
    "display(VBox([controls, output])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the threshold parameters that will be used to define the spot selection criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section saves the parameters adjusted in the previous widget in two variables that will be use for the rest of the code.\n",
    "selected_intensity = interactive_plot_tr.kwargs_widgets[1].value\n",
    "selected_size = interactive_plot_tr.kwargs_widgets[2].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detecting the spots in all frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"f\" is a pandas data frame that contains the information about the detected spots.\n",
    "# tp.batch is a trackpy function that detects spots for multiple frames in a video.\n",
    "f = tp.batch(video[:,:,:,0],selected_size, minmass=selected_intensity,percentile=70)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing particles outside the mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spots_in_mask(f,mask):\n",
    "    # extracting the contours in the image\n",
    "    coords = np.array([f.y, f.x]).T # These are the points detected by trackpy\n",
    "    coords_int = np.round(coords).astype(int)  # or np.floor, depends\n",
    "    values_at_coords = mask[tuple(coords_int.T)] # If 1 the value is in the mask\n",
    "    f['In Mask']=values_at_coords # Check if pts are on/in polygon mask  \n",
    "    return f "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = spots_in_mask(f,mask) \n",
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_particles_in_mask = f[f['In Mask']==True]\n",
    "dataframe_particles_in_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking all detected spots across all frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp.link_df is a trackpy function that links spots detected in multiple frames, this generates the spots trajectories in time.\n",
    "df_linked_particles = tp.link_df(dataframe_particles_in_mask,5, memory=2) # tp.link_df(data_frame, max_distance_particle_moves, max_time_particle_vanishes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating spurious trajectories. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trackpy.filtering.filter_stubs(tracks, threshold=100)\n",
    "df_linked_particles_filtered = tp.filter_stubs(df_linked_particles, 2)  # selecting trajectories that appear in at least 10 frames.\n",
    "# Compare the number of particles in the unfiltered and filtered data.\n",
    "print('Before:', df_linked_particles['particle'].nunique())\n",
    "print('After:', df_linked_particles_filtered['particle'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional section that saves the particles trajectories and intensities as a CSV file\n",
    "df_linked_particles_filtered.to_csv('tracking_particles.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with trajectories\n",
    "____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the intensity values for particles with intensity higher than a threshold and in frame 0\n",
    "df_linked_particles_filtered.loc[(df_linked_particles_filtered['mass']>=1000) & (df_linked_particles_filtered['frame']==0)  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting trajectories in x-y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting \n",
    "plt.figure(figsize=(5,5))\n",
    "for i in range(0,df_linked_particles_filtered['particle'].nunique() ):\n",
    "    x_val = df_linked_particles_filtered.loc[df_linked_particles_filtered['particle']==i ].x.values[:]\n",
    "    y_val = df_linked_particles_filtered.loc[df_linked_particles_filtered['particle']==i ].y.values[:]\n",
    "    plt.plot(x_val,y_val, '-',linewidth = 3 )\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "plt.title('Particle movement 2D')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting trajectories versus intensity using trackpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the number of detected spots.\n",
    "n_particles = df_linked_particles_filtered['particle'].nunique()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10,5))\n",
    "for id in range(0,n_particles):\n",
    "    plt.plot(df_linked_particles_filtered.loc[df_linked_particles_filtered['particle']==df_linked_particles_filtered['particle'].unique()[id]].frame, df_linked_particles_filtered.loc[df_linked_particles_filtered['particle']==df_linked_particles_filtered['particle'].unique()[id]].mass )\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Intensity a.u.')\n",
    "plt.title('Intensity vs Time')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('rsnaped_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "daf7c258a197027f92a823c5e9002157216e53cdde30f9077602d149eebf1043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

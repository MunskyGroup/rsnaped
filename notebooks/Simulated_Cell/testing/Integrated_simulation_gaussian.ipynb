{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "immune-rogers",
   "metadata": {},
   "source": [
    "# Integrated Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os; from os import listdir; from os.path import isfile, join\n",
    "import re  \n",
    "from skimage import io \n",
    "from skimage.io import imread\n",
    "cwd = os.getcwd(); os.chdir('../../rsnaped');import rsnaped as rsp; os.chdir(cwd)\n",
    "from tqdm.notebook import tqdm\n",
    "# To manipulate arrays\n",
    "import numpy as np \n",
    "import random\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import shutil\n",
    "# Plotting\n",
    "import matplotlib as mpl ; import matplotlib.pyplot as plt \n",
    "# To create interactive elements\n",
    "import ipywidgets as widgets ; from ipywidgets import interact, interactive, fixed, interact_manual, Button, HBox, VBox, Layout, GridspecLayout ; from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters that need to be tested. \n",
    "number_of_simulated_cells = 2  # PLEASE TEST MIN 1 MAX 10\n",
    "number_spots_per_cell = 38     # PLEASE TEST MIN 5 MAX 200\n",
    "simulation_time_in_sec = 15     # PLEASE TEST MIN 10 MAX 100\n",
    "diffusion_coefficient = 0.5      # PLEASE TEST MIN 0.1 MAX 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_calculation_method = 'gaussian_fit'  # options are : 'total_intensity' and 'disk_donut' 'gaussian_fit'\n",
    "mask_selection_method = 'max_area' # options are : 'max_spots' and 'max_area' \n",
    "use_optimization_for_tracking =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hearing-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_size = 5 # spot size for the simulation and tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-justice",
   "metadata": {},
   "source": [
    "## Running the simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_simulated_cells(number_of_simulated_cells=3,number_spots_per_cell=80,simulation_time_in_sec =100,step_size_in_sec=1,particle_size=5, diffusion_coefficient =1,path_to_rSNAPsim= None, path_to_save_output='./temp',intensity_calculation_method='gaussian_fit'):\n",
    "    spot_size = particle_size\n",
    "    spot_sigma = 2\n",
    "\n",
    "    # Code that creates the folder to store results.\n",
    "    diffusion_coefficient_string = str(diffusion_coefficient).replace('.','_')\n",
    "    directory_name = '/Simulation_V2__'+'ns_'+str(number_spots_per_cell) +'_diff_'+ diffusion_coefficient_string \n",
    "    path_to_save_output = './temp'\n",
    "    save_to_path =  path_to_save_output + directory_name \n",
    "    \n",
    "    if not os.path.exists(save_to_path):\n",
    "        os.makedirs(save_to_path)\n",
    "    else:\n",
    "        shutil.rmtree(save_to_path)\n",
    "        os.makedirs(save_to_path)\n",
    "    \n",
    "    # Loading trajectories from file\n",
    "    ssa_trajectories = np.load('../../DataBases/rsnapsim_simulations/bactin_ssa.npy')\n",
    "    \n",
    "    counter = 0\n",
    "    ## Main loop that creates each cell and dataframe\n",
    "    for cell_number in range (0, number_of_simulated_cells):\n",
    "        ouput_directory_name = '../../DataBases/videos_for_sim_cell'\n",
    "        list_files_names = sorted([f for f in listdir(ouput_directory_name) if isfile(join(ouput_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "        list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "        path_files = [ ouput_directory_name+'/'+f for f in list_files_names ] # creating the complete path for each file\n",
    "        video_path = path_files[counter]        \n",
    "        video = io.imread(video_path) \n",
    "        # Normalization to remove extreme values.\n",
    "        #mean_int_video = np.mean(video[0,:,:,1])\n",
    "        #video = rsp.RemoveExtrema (video, min_percentile=0, max_percentile=99.5,ignore_channel =2).remove_outliers()\n",
    "        \n",
    "        # Scale video intensity \n",
    "        #if mean_int_video < 3000:\n",
    "        #    scale_percentage_value =0.8\n",
    "        #else:\n",
    "        #    scale_percentage_value =0.5\n",
    "        #video = rsp.ScaleIntensity( video, scale_percentage=scale_percentage_value).apply_scale()\n",
    "        counter +=1\n",
    "        if counter>=len(path_files):\n",
    "            counter =0\n",
    "        random_index_ch1 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "        random_index_ch2 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "        simulated_trajectories_ch1 = ssa_trajectories[random_index_ch1,0:simulation_time_in_sec:step_size_in_sec]\n",
    "        simulated_trajectories_ch2 =  ssa_trajectories[random_index_ch2,0:simulation_time_in_sec:step_size_in_sec]\n",
    "        # Simulations for intensity\n",
    "#        ssa1 = rss.ssa_solver(n_traj = number_spots, start_time=starting_time,tf=starting_time+n_frames, tstep=starting_time+n_frames,k_elong_mean=3, k_initiation=.03)  # tstep = total number of steps including the burnin time \n",
    "#        simulated_trajectories = ssa1.intensity_vec\n",
    "#        ssa2 = rss.ssa_solver(n_traj = number_spots, start_time=starting_time,tf=starting_time+n_frames, tstep=starting_time+n_frames,k_elong_mean=3, k_initiation=.03)  # tstep = total number of steps including the burnin time \n",
    "#        simulated_trajectories_blue = ssa2.intensity_vec\n",
    "        # simulated trajectories for the green and blue channels\n",
    "#        simulated_trajectories_ch2 = simulated_trajectories\n",
    "#        simulated_trajectories_ch3 = simulated_trajectories_blue\n",
    "        # Running the cell simulation\n",
    "        saved_file_name = save_to_path+'/sim_cell_'+str(cell_number)\n",
    "        tensor_video , tensor_for_image_j , spot_positions_movement, tensor_mean_intensity_in_figure, tensor_std_intensity_in_figure, DataFrame_particles_intensities = rsp.SimulatedCell( base_video=video, number_spots = number_spots_per_cell, number_frames=simulation_time_in_sec, step_size=step_size_in_sec, diffusion_coefficient =diffusion_coefficient, simulated_trajectories_ch0=None, size_spot_ch0=spot_size, spot_sigma_ch0=spot_sigma, simulated_trajectories_ch1=simulated_trajectories_ch1, size_spot_ch1=spot_size, spot_sigma_ch1=spot_sigma, simulated_trajectories_ch2=simulated_trajectories_ch2, size_spot_ch2=spot_size, spot_sigma_ch2=spot_sigma, ignore_ch0=0,ignore_ch1=0, ignore_ch2=1,save_as_tif_uint8=0,save_as_tif =1,save_as_gif=0, save_dataframe=1, saved_file_name=saved_file_name,create_temp_folder = False, intensity_calculation_method=intensity_calculation_method).make_simulation()      \n",
    "        print ('The results are saved in folder: ', saved_file_name)\n",
    "    return save_to_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amended-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the simulation\n",
    "ouput_directory_name = fun_simulated_cells(number_of_simulated_cells=number_of_simulated_cells,number_spots_per_cell=number_spots_per_cell,simulation_time_in_sec =simulation_time_in_sec,step_size_in_sec=1,particle_size=particle_size, diffusion_coefficient=diffusion_coefficient,path_to_rSNAPsim= None,intensity_calculation_method=intensity_calculation_method)\n",
    "path = ouput_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjacent-effect",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouput_directory_name='./temp/Simulation_V2__ns_40_diff_0_5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "delayed-madagascar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the folder with the results and import the simulations as lists\n",
    "list_files_names = sorted([f for f in listdir(ouput_directory_name) if isfile(join(ouput_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files = [ ouput_directory_name+'/'+f for f in list_files_names ] # creating the complete path for each file\n",
    "# Reading the microscopy data\n",
    "list_videos = [imread(f)[:,:,:,:] for f in  path_files] # List with all the videos\n",
    "nimg = number_of_simulated_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-synthesis",
   "metadata": {},
   "source": [
    "## Display results as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the simulated images\n",
    "rsp.VisualizerImage(list_videos,list_files_names,selected_channel =0,selected_timepoint= 0,normalize=1,individual_figure_size=7).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unable-jimmy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#intensity_selection_method =intensity_selection_method, mask_selection_method = mask_selection_method\n",
    "list_DataFrame_particles_intensities= []\n",
    "list_array_intensities = []\n",
    "list_time_vector = []\n",
    "for i in tqdm(range(0,nimg)): \n",
    "    DataFrame_particles_intensities, array_intensities, time_vector, mean_intensities,std_intensities, mean_intensities_normalized, std_intensities_normalized = rsp.PipelineTracking(list_videos[i],particle_size=particle_size,file_name=list_files_names[i],selected_channel=0,intensity_calculation_method =intensity_calculation_method, mask_selection_method = mask_selection_method,show_plot=1,use_optimization_for_tracking=use_optimization_for_tracking).run()    \n",
    "    list_DataFrame_particles_intensities.append(DataFrame_particles_intensities)\n",
    "    list_array_intensities.append(array_intensities)\n",
    "    list_time_vector.append(time_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-daily",
   "metadata": {},
   "source": [
    "# Comparing intensity distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effective-baptist",
   "metadata": {},
   "source": [
    "## \"Real\" intensities from SSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-ladder",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_timepoint = simulation_time_in_sec-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-lexington",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extrema(vector,min_percentile = 2 ,max_percentile = 98):\n",
    "    '''This function is intended to remove extrema data given by the min and max percentiles specified by the user'''\n",
    "    vector = vector [vector>0]\n",
    "    max_val = np.percentile(vector, max_percentile)\n",
    "    min_val =  np.percentile(vector, min_percentile)\n",
    "    print(round(min_val,2),round(max_val,2))\n",
    "    new_vector = vector [vector< max_val] # = np.percentile(vector,max_percentile)\n",
    "    new_vector = new_vector [new_vector> min_val] # = np.percentile(vector, min_percentile)\n",
    "    return new_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-processing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ssa_trajectories = np.load('../../DataBases/rsnapsim_simulations/bactin_ssa.npy')\n",
    "ssa_trajectories = np.load('../../DataBases/rsnapsim_simulations/bactin_ssa.npy')\n",
    "ssa_trajectories_timePoint = ssa_trajectories[:,sel_timepoint].flatten()\n",
    "#ssa_trajectories_timePoint= remove_extrema(ssa_trajectories_timePoint)\n",
    "ssa_trajectories_timePoint_normalized = (ssa_trajectories_timePoint-np.amin(ssa_trajectories_timePoint))/ (np.amax(ssa_trajectories_timePoint)-np.amin(ssa_trajectories_timePoint))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-pillow",
   "metadata": {},
   "source": [
    "## Recovered intensities from tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cells_green_int = np.array([])\n",
    "for i in range(0,nimg): \n",
    "    all_cells_green_int = np.append(all_cells_green_int,list_array_intensities[i][:,sel_timepoint,1].flatten())   \n",
    "all_cells_green_int = all_cells_green_int[all_cells_green_int>0]\n",
    "all_cells_green_int= remove_extrema(all_cells_green_int)\n",
    "all_cells_green_int_normalized = (all_cells_green_int-np.amin(all_cells_green_int))/ (np.amax(all_cells_green_int)-np.amin(all_cells_green_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-great",
   "metadata": {},
   "source": [
    "## Loading intensities from image. \"Perfect tracking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-robinson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the number of real simulations from folder name\n",
    "ind_str_start = path.find('_ns_') +4\n",
    "ind_str_end = path.find('_diff') \n",
    "max_nspots = int(path[ind_str_start:ind_str_end])\n",
    "intensity_values_in_image = np.zeros((nimg,max_nspots)) # prealocating memory\n",
    "for i in range(0,nimg):\n",
    "    for j in range (0,max_nspots):\n",
    "        file_name = path+'/sim_cell_'+str(i)+'_df.csv'\n",
    "        df_intensities_real = pd.read_csv(file_name)  \n",
    "        intensity_values_in_image[i,j] = df_intensities_real[df_intensities_real['particle'] ==j].green_int_mean.values[sel_timepoint]         \n",
    "intensity_values_in_image_flat = intensity_values_in_image.flatten()\n",
    "intensity_values_in_image_flat =  intensity_values_in_image_flat[intensity_values_in_image_flat>0]\n",
    "intensity_values_in_image_flat= remove_extrema(intensity_values_in_image_flat)\n",
    "intensity_values_in_image_normalized = (intensity_values_in_image_flat-np.amin(intensity_values_in_image_flat))/ (np.amax(intensity_values_in_image_flat)-np.amin(intensity_values_in_image_flat)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-script",
   "metadata": {},
   "source": [
    "# Intensity histograms with au"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "axes[0].hist(ssa_trajectories_timePoint,bins=60,density=True, stacked=True, color='orangered' )     \n",
    "axes[0].set(title='SSA')\n",
    "axes[0].set(xlabel='intensities (ump)')\n",
    "axes[0].set(ylabel='count')\n",
    "\n",
    "axes[1].hist(all_cells_green_int,bins=60,density=True, stacked=True, color='chartreuse' )     \n",
    "axes[1].set(title='Tracking')\n",
    "axes[1].set(xlabel='intensities (au)')\n",
    "axes[1].set(ylabel='count')\n",
    "\n",
    "axes[2].hist(intensity_values_in_image_flat,bins=60,density=True, stacked=True, color='cyan' )     \n",
    "axes[2].set(title='Image')\n",
    "axes[2].set(xlabel='intensities (au)')\n",
    "axes[2].set(ylabel='count')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-aside",
   "metadata": {},
   "source": [
    "## Normalizing intensities to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "general-lincoln",
   "metadata": {},
   "source": [
    "$ X_{norm} = \\frac{X -min(X)}{max(X) - min(X)} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting normalized intensities\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "axes[0].hist(ssa_trajectories_timePoint_normalized,bins=60,density=True, stacked=True, color='orangered' )     \n",
    "axes[0].set(title='SSA')\n",
    "axes[0].set(xlabel='intensities (norm)')\n",
    "axes[0].set(ylabel='count')\n",
    "\n",
    "axes[1].hist(all_cells_green_int_normalized,bins=60,density=True, stacked=True, color='chartreuse' )     \n",
    "axes[1].set(title='Tracking')\n",
    "axes[1].set(xlabel='intensities (norm)')\n",
    "axes[1].set(ylabel='count')\n",
    "\n",
    "axes[2].hist(intensity_values_in_image_normalized,bins=60,density=True, stacked=True, color='cyan' )     \n",
    "axes[2].set(title='Image')\n",
    "axes[2].set(xlabel='intensities (au)')\n",
    "axes[2].set(ylabel='count')\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-aaron",
   "metadata": {},
   "source": [
    "## Cummulative frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "data1 = ssa_trajectories_timePoint_normalized\n",
    "data_sorted_1 = np.sort(data1)\n",
    "p_1 =np.linspace(0, 1, len(data1), endpoint=False)\n",
    "\n",
    "data2 = all_cells_green_int_normalized\n",
    "data_sorted_2 = np.sort(data2)\n",
    "p_2 =np.linspace(0, 1, len(data2), endpoint=False)\n",
    "\n",
    "data3 = intensity_values_in_image_normalized\n",
    "data_sorted_3 = np.sort(data3)\n",
    "p_3 =np.linspace(0, 1, len(data3), endpoint=False)\n",
    "\n",
    "# Plotting\n",
    "plt.plot(data_sorted_1, p_1, 'orangered',linewidth=3,label ='SSA')\n",
    "plt.plot(data_sorted_2, p_2,'chartreuse',linewidth=3,label ='tracking')\n",
    "plt.plot(data_sorted_3, p_3,'cyan',linewidth=3,label ='Image')\n",
    "\n",
    "plt.legend()\n",
    "plt.title('cumfreq');\n",
    "plt.ylabel('Cumulative probability');\n",
    "plt.xlabel('Normalized intensity');\n",
    "plt.show()\n",
    "\n",
    "# Print number of spots\n",
    "\n",
    "print('Number of spots for SSA:',len(data1))\n",
    "print('Number of spots recovered from tracking:',len(data2))\n",
    "print('Number of spots recovered from image:',len(data3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-prospect",
   "metadata": {},
   "source": [
    "## Comparison using the KS-distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-bobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating Kolmogorov distance\n",
    "\n",
    "ks_distance = scipy.stats.kstest(data1,data2).statistic\n",
    "print('The KS-distance between SSA and tracking is:' , round(ks_distance,2))\n",
    "\n",
    "ks_distance = scipy.stats.kstest(data1,data3).statistic\n",
    "print('The KS-distance between SSA and image is:' , round(ks_distance,2))\n",
    "\n",
    "#ks_distance = scipy.stats.kstest(data3,data2).statistic\n",
    "#print('The KS-distance between image and tracking is:' , round(ks_distance,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan for the next two weeks.\n",
    "    # Migrate all data to new repository  ==> done\n",
    "    # More testing with real data\n",
    "    # calculate tracking and detection quality\n",
    "    # beta version\n",
    "    # Notebooks for particle tracking\n",
    "    # Notebooks for FISH detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artificial-measurement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "enormous-large",
   "metadata": {},
   "source": [
    "# Integrated Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "heated-sucking",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os; from os import listdir; from os.path import isfile, join\n",
    "import re  \n",
    "from skimage import io \n",
    "from skimage.io import imread\n",
    "cwd = os.getcwd(); os.chdir('../../rsnaped');import rsnaped as rsp; os.chdir(cwd)\n",
    "from tqdm.notebook import tqdm\n",
    "# To manipulate arrays\n",
    "import numpy as np \n",
    "import random\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import shutil\n",
    "# Plotting\n",
    "import matplotlib as mpl ; import matplotlib.pyplot as plt \n",
    "# To create interactive elements\n",
    "import ipywidgets as widgets ; from ipywidgets import interact, interactive, fixed, interact_manual, Button, HBox, VBox, Layout, GridspecLayout ; from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "opposed-conflict",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the parameters that need to be tested. \n",
    "number_of_simulated_cells = 8*10 # PLEASE TEST MIN 1 MAX 10\n",
    "number_spots_per_cell = 29     # PLEASE TEST MIN 5 MAX 200\n",
    "simulation_time_in_sec = 2     # PLEASE TEST MIN 10 MAX 100\n",
    "diffusion_coefficient = 0.5      # PLEASE TEST MIN 0.1 MAX 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "split-translation",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_calculation_method = 'disk_donut'  # options are : 'total_intensity' and 'disk_donut' 'gaussian_fit'\n",
    "mask_selection_method = 'max_area' # options are : 'max_spots' and 'max_area' \n",
    "use_optimization_for_tracking = 0 # 0 not using, 1 is using optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "asian-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "particle_size = 5 # spot size for the simulation and tracking.\n",
    "elongation_rate = 3\n",
    "initiation_rate = 0.03\n",
    "frame_selection_empty_video = 'loop' # Options are: 'constant' , 'shuffle' and 'loop'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-beijing",
   "metadata": {},
   "source": [
    "## Running the simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "first-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun_simulated_cells(number_of_simulated_cells=3,number_spots_per_cell=80,simulation_time_in_sec =100,step_size_in_sec=1,particle_size=5, diffusion_coefficient =1,path_to_rSNAPsim= None, path_to_save_output='./temp',intensity_calculation_method='gaussian_fit',frame_selection_empty_video=frame_selection_empty_video):\n",
    "    spot_size = particle_size\n",
    "    spot_sigma = 2\n",
    "    # Code that creates the folder to store results.\n",
    "    diffusion_coefficient_string = str(diffusion_coefficient).replace('.','_')\n",
    "    directory_name = '/Simulation_V2__'+'ns_'+str(number_spots_per_cell) +'_diff_'+ diffusion_coefficient_string \n",
    "    path_to_save_output = './temp'\n",
    "    save_to_path =  path_to_save_output + directory_name \n",
    "    if not os.path.exists(save_to_path):\n",
    "        os.makedirs(save_to_path)\n",
    "    else:\n",
    "        shutil.rmtree(save_to_path)\n",
    "        os.makedirs(save_to_path)\n",
    "    # Loading trajectories from file\n",
    "    ssa_trajectories = np.load('../../DataBases/rsnapsim_simulations/bactin_ssa.npy')\n",
    "    counter = 0\n",
    "    ## Main loop that creates each cell and dataframe\n",
    "    for cell_number in range (0, number_of_simulated_cells):\n",
    "        ouput_directory_name = '../../DataBases/videos_for_sim_cell'\n",
    "        list_files_names = sorted([f for f in listdir(ouput_directory_name) if isfile(join(ouput_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "        list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "        path_files = [ ouput_directory_name+'/'+f for f in list_files_names ] # creating the complete path for each file\n",
    "        video_path = path_files[counter]\n",
    "        video = io.imread(video_path) \n",
    "        counter +=1\n",
    "        if counter>=len(path_files):\n",
    "            counter =0\n",
    "        random_index_ch1 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "        random_index_ch2 = np.random.randint(low=0, high=ssa_trajectories.shape[0]-1, size=(number_spots_per_cell,))\n",
    "        simulated_trajectories_ch1 = ssa_trajectories[random_index_ch1,0:simulation_time_in_sec:step_size_in_sec]\n",
    "        simulated_trajectories_ch2 =  ssa_trajectories[random_index_ch2,0:simulation_time_in_sec:step_size_in_sec]\n",
    "        # Simulations for intensity\n",
    "#        ssa1 = rss.ssa_solver(n_traj = number_spots, start_time=starting_time,tf=starting_time+n_frames, tstep=starting_time+n_frames,k_elong_mean=3, k_initiation=.03)  # tstep = total number of steps including the burnin time \n",
    "#        simulated_trajectories = ssa1.intensity_vec\n",
    "#        ssa2 = rss.ssa_solver(n_traj = number_spots, start_time=starting_time,tf=starting_time+n_frames, tstep=starting_time+n_frames,k_elong_mean=3, k_initiation=.03)  # tstep = total number of steps including the burnin time \n",
    "#        simulated_trajectories_blue = ssa2.intensity_vec\n",
    "        # simulated trajectories for the green and blue channels\n",
    "#        simulated_trajectories_ch2 = simulated_trajectories\n",
    "#        simulated_trajectories_ch3 = simulated_trajectories_blue\n",
    "        # Running the cell simulation\n",
    "        saved_file_name = save_to_path+'/sim_cell_'+str(cell_number)\n",
    "        tensor_video , tensor_for_image_j , spot_positions_movement, tensor_mean_intensity_in_figure, tensor_std_intensity_in_figure, DataFrame_particles_intensities = rsp.SimulatedCell( base_video=video, number_spots = number_spots_per_cell, number_frames=simulation_time_in_sec, step_size=step_size_in_sec, diffusion_coefficient =diffusion_coefficient, simulated_trajectories_ch0=None, size_spot_ch0=spot_size, spot_sigma_ch0=spot_sigma, simulated_trajectories_ch1=simulated_trajectories_ch1, size_spot_ch1=spot_size, spot_sigma_ch1=spot_sigma, simulated_trajectories_ch2=simulated_trajectories_ch2, size_spot_ch2=spot_size, spot_sigma_ch2=spot_sigma, ignore_ch0=0,ignore_ch1=0, ignore_ch2=1,save_as_tif_uint8=0,save_as_tif =1,save_as_gif=0, save_dataframe=1, saved_file_name=saved_file_name,create_temp_folder = False, intensity_calculation_method=intensity_calculation_method,perform_video_augmentation=1,frame_selection_empty_video=frame_selection_empty_video).make_simulation()      \n",
    "        #print ('The results are saved in folder: ', saved_file_name)\n",
    "    return save_to_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-corrections",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running the simulation\n",
    "start = timer()\n",
    "ouput_directory_name = fun_simulated_cells(number_of_simulated_cells=number_of_simulated_cells,number_spots_per_cell=number_spots_per_cell,simulation_time_in_sec =simulation_time_in_sec,step_size_in_sec=1,particle_size=particle_size, diffusion_coefficient=diffusion_coefficient,path_to_rSNAPsim= None,intensity_calculation_method=intensity_calculation_method,frame_selection_empty_video=frame_selection_empty_video)\n",
    "end = timer()\n",
    "print('Time to generte simulated data:',round((end - start)/60), ' min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-adapter",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ouput_directory_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southeast-difference",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Reads the folder with the results and import the simulations as lists\n",
    "list_files_names = sorted([f for f in listdir(ouput_directory_name) if isfile(join(ouput_directory_name, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files = [ ouput_directory_name+'/'+f for f in list_files_names ] # creating the complete path for each file\n",
    "# Reading the microscopy data\n",
    "list_videos = [imread(f)[:,:,:,:] for f in  path_files] # List with all the videos\n",
    "nimg = number_of_simulated_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunrise-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the dataframes\n",
    "list_files_dfnames = sorted([f for f in listdir(ouput_directory_name) if isfile(join(ouput_directory_name, f)) and ('.csv') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_dfnames.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files_df = [ ouput_directory_name+'/'+f for f in list_files_dfnames ] # creating the complete path for each file\n",
    "list_df_real_positions = [pd.read_csv(f) for f in  path_files_df] # List with all the videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-recovery",
   "metadata": {},
   "source": [
    "## Display results as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-glass",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing the simulated images\n",
    "rsp.VisualizerImage(list_videos,list_files_names=list_files_names,selected_channel =1,selected_timepoint= 1,normalize=0,individual_figure_size=4).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "rsp.VisualizerImage(list_videos,list_selected_particles_dataframe = list_df_real_positions,list_files_names=list_files_names,selected_channel =0,selected_timepoint= 1,normalize=0,individual_figure_size=4).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-venue",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

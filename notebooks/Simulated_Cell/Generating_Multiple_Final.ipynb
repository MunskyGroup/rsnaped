{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os; from os import listdir; from os.path import isfile, join\n",
    "import re  \n",
    "from skimage.io import imread\n",
    "from scipy import ndimage\n",
    "import trackpy as tp\n",
    "from cellpose import models\n",
    "from cellpose import plot\n",
    "from matplotlib import gridspec\n",
    "import math\n",
    "import seaborn as sn                       \n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from numpy import unravel_index\n",
    "# To manipulate arrays\n",
    "import numpy as np \n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "from timeit import default_timer as timer\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import pathlib\n",
    "import tifffile\n",
    "import sys\n",
    "from skimage.exposure import rescale_intensity\n",
    "import rsnapsim as rss\n",
    "# Importing libraries with the watershed algorithm and local maximum detection\n",
    "from scipy import ndimage as ndi              # Distance Transform\n",
    "from skimage.feature import peak_local_max    # Local maxima in a matrix\n",
    "from skimage.segmentation import watershed    # Watershed algorithm\n",
    "from skimage.filters import gaussian # Module working with a gaussian filter\n",
    "from skimage.draw import polygon\n",
    "from skimage import measure\n",
    "# Plotting\n",
    "import matplotlib as mpl ; import matplotlib.pyplot as plt \n",
    "# To create interactive elements\n",
    "import ipywidgets as widgets ; from ipywidgets import interact, interactive, fixed, interact_manual, Button, HBox, VBox, Layout, GridspecLayout ; from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Defining directories\n",
    "current_dir = pathlib.Path().absolute()\n",
    "sequences_dir = current_dir.parents[1].joinpath('DataBases','gene_files')\n",
    "video_dir = current_dir.parents[1].joinpath('DataBases','moving_cells')\n",
    "masks_dir = current_dir.parents[1].joinpath('DataBases','masks_for_sim_cell')\n",
    "trajectories_dir = current_dir.parents[1].joinpath('DataBases','rsnapsim_simulations','kdm5b_ssa.npy')\n",
    "rsnaped_dir = current_dir.parents[1].joinpath('rsnaped')\n",
    "gene_file = current_dir.parents[1].joinpath('DataBases','gene_files','KDM5B_withTags.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4bed71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import rsnaped as rsp\n",
    "sys.path.append(str(rsnaped_dir))\n",
    "import rsnaped as rsp\n",
    "rsp.Banner(show=True).print_banner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f287e715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all video in dir\n",
    "list_files_names = sorted([f for f in listdir(video_dir) if isfile(join(video_dir, f)) and ('.tif') in f], key=str.lower)  # reading all tif files in the folder\n",
    "list_files_names.sort(key=lambda f: int(re.sub('\\D', '', f)))  # sorting the index in numerical order\n",
    "path_files = [ str(video_dir.joinpath(f).resolve()) for f in list_files_names ] # creating the complete path for each file\n",
    "path_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c9db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = pathlib.Path(path_files[0])\n",
    "video = imread(str(file_path)) \n",
    "img = np.expand_dims(video,axis=3)\n",
    "image_optimization= np.concatenate((img,img),axis=3)\n",
    "\n",
    "number_optimization_steps = 20\n",
    "\n",
    "int_threshold_vector = np.round(np.linspace(0.1, 1.5, num=number_optimization_steps, endpoint=True,dtype=float),2)\n",
    "cell_size_vector = np.linspace(60, 120, num=number_optimization_steps, endpoint=True,dtype=int)\n",
    "model = models.Cellpose(gpu=True, model_type='nuclei') # model_type='cyto' or model_type='nuclei'\n",
    "NUMBER_OF_CORES = np.min((2,multiprocessing.cpu_count()))\n",
    "#NUMBER_OF_CORES = multiprocessing.cpu_count()\n",
    "\n",
    "print(int_threshold_vector)\n",
    "print(cell_size_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c743318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the intensity distribution for a specific time point and an specific channel\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.hist(image_optimization[0,:,:,0].flatten(), bins=80,color='orangered')\n",
    "plt.xlabel('Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.ylim(0,1e5)\n",
    "plt.title('Intensity Histogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d56945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cells_center_of_mass(list_masks_for_all_frames):\n",
    "    # Creating dataframe with centers of mass\n",
    "    list_df=[]\n",
    "    number_frames= list_masks_for_all_frames.shape[0]\n",
    "    for i in range(number_frames):\n",
    "        number_cells_in_frame = list_masks_for_all_frames[i].max()\n",
    "        for m in range (1, number_cells_in_frame+1):\n",
    "            selected_mask = np.where(list_masks_for_all_frames[i]==m,1,0) # Selecting only one mask.  \n",
    "            x,y = ndimage.measurements.center_of_mass(selected_mask)\n",
    "            list_df.append( [i,int(x),int(y)] )\n",
    "            del x, y, selected_mask\n",
    "    return np.array(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mask_labels (masks,tracking_dataframe):\n",
    "    list_df=[]\n",
    "    number_frames= masks.shape[0]\n",
    "    list_new_masks= []\n",
    "    for i in range(0,number_frames):\n",
    "        # creating a copy of the original image\n",
    "        temp_image = np.zeros_like(masks[0,:,:])\n",
    "        trackpy_labels = tracking_dataframe.loc[tracking_dataframe['frame']==i ].particle.values\n",
    "        \n",
    "        # Iterate for each cell in \n",
    "        number_cells_in_frame = masks[i].max()\n",
    "        for m in range (1, number_cells_in_frame+1):\n",
    "            selected_mask = np.where(masks[i]==m,1,0) # Selecting only one mask.  \n",
    "            for index, particle_label in enumerate (trackpy_labels):\n",
    "                # Test if the center of mass is inside the selected mask \n",
    "                y, x = tracking_dataframe.loc[(tracking_dataframe['frame']==i ) & (tracking_dataframe['particle']==particle_label) , ['y', 'x']].values[0]\n",
    "                if selected_mask[y,x]==1:\n",
    "                    temp_image = np.where(selected_mask==1, particle_label,temp_image)\n",
    "        list_new_masks.append(temp_image)\n",
    "    return np.array(list_new_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8d671",
   "metadata": {},
   "outputs": [],
   "source": [
    "def watershed_segmentation(img,min_distance=50):\n",
    "    mask_image = img.copy()\n",
    "    mask_image = (mask_image/mask_image.max()) * 255\n",
    "    #mask_image[mask_image>=threshold] =255    \n",
    "    plt.imshow(mask_image)\n",
    "    new_mask = gaussian(mask_image, sigma=4) # applying the gaussian filter\n",
    "    contours = measure.find_contours(new_mask, level=100, fully_connected='high') # Finding the contours in the image    \n",
    "    # Connecting the last and first  elements in the array (contours) to get a fully connected shape\n",
    "    contours_connected = np.vstack((contours))\n",
    "    contours_connected = np.vstack((contours_connected[-1,:],contours_connected))\n",
    "    # make a new mask from the contours array\n",
    "    watershed_starting_mask = np.zeros(img.shape).astype(int)                    # Prealocating an array with zeros. Notice the datatype.\n",
    "    rr, cc = polygon(contours_connected[:,0], contours_connected[:,1])   # Returns the coordinates inside the contour\n",
    "    watershed_starting_mask[rr,cc] = 1   \n",
    "    #Computes the Distance Transform distance in the image\n",
    "    distance = - ndi.distance_transform_edt(watershed_starting_mask)        \n",
    "    # Apply watershed\n",
    "    distance = ndi.distance_transform_edt(watershed_starting_mask)                       # Computes the Distance Transform distance in the image\n",
    "    coords = peak_local_max(distance, min_distance=min_distance, labels=watershed_starting_mask)   # Use the Distance transform image to find local maxima\n",
    "    _,inds = np.unique(distance[coords[:,0],coords[:,1]],return_index=True)      # Make sure they are unique\n",
    "    coords = coords[inds,:]                                                      # Selecting unique indexes\n",
    "    mask = np.zeros(distance.shape, dtype=bool)                                  # Prealocating an array with zeros\n",
    "    mask[tuple(coords.T)] = True                                                 # Make an image with 1's where local maxima are\n",
    "    markers, _ = ndi.label(mask)                                                 # Unique values used as the desired labels\n",
    "    # Using the watershed algorithm\n",
    "    labels = watershed(-distance, markers, mask=watershed_starting_mask, watershed_line=True)  \n",
    "\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e07193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intensity_percentile_threshold = 95\n",
    "# image_test = image_optimization.copy() # Making a copy of our img\n",
    "# image_test[image_test>np.percentile(image_test,intensity_percentile_threshold)]=np.percentile(image_test,intensity_percentile_threshold)  # threshold image values larger than 1000 equal to 1000\n",
    "# image_test = (image_test/image_test.max()) * 255\n",
    "# labels = watershed_segmentation(image_test[10,:,:,1])\n",
    "# plt.imshow(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b3dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cellpose_segmentation(img,cell_size,model,int_threshold_vector):\n",
    "    mask, _, _, _ = model.eval(img, diameter=cell_size, min_size=2000, channels=[0,0], net_avg=False, augment=False,flow_threshold=int_threshold_vector)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9d8094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cell_segmentation_optimized (image_to_segment,model, intensity_percentile_threshold=99,cell_size=100,minimal_trajectory_length=10, memory_tracking=0,masks_with_trackpy_labels= True,use_cellpose=True,min_distance=100): \n",
    "    # optimization code to detected cells using multiple intensity thresholds\n",
    "    image_test = image_to_segment.copy() # Making a copy of our img\n",
    "    image_test[image_test>np.percentile(image_test,96)]=np.percentile(image_test,96)  # threshold image values larger than 1000 equal to 1000\n",
    "    \n",
    "    if use_cellpose == True:\n",
    "        list_masks = Parallel(n_jobs = NUMBER_OF_CORES)(delayed(cellpose_segmentation)(image_test[index_cellpose,:,:,:],cell_size,model,intensity_percentile_threshold) for index_cellpose in range(0,image_test.shape[0]))\n",
    "        masks_for_all_frames = np.array(list_masks)\n",
    "    else:\n",
    "        list_masks = Parallel(n_jobs = NUMBER_OF_CORES)(delayed(watershed_segmentation)(image_test[index_cellpose,:,:,0]) for index_cellpose in range(0,image_test.shape[0]))\n",
    "        masks_for_all_frames = np.array(list_masks)\n",
    "    try:\n",
    "        area_every_frame = np.count_nonzero(masks_for_all_frames, axis=0)\n",
    "        array_center_mass = cells_center_of_mass(masks_for_all_frames)\n",
    "        df = pd.DataFrame(array_center_mass, columns=['frame', 'y', 'x'])\n",
    "        t = tp.link(df, memory=memory_tracking,search_range=80)\n",
    "        t_filtered = tp.filter_stubs(t, minimal_trajectory_length)  # selecting trajectories that appear in at least 10 frames.\n",
    "        num_detected_cells = t_filtered['particle'].nunique()-1 # removing the value for the empty cell\n",
    "        \n",
    "        # reordering the index for the particles to have consecutive numbers\n",
    "        particle_index_trackpy_values = np.unique(t_filtered['particle'].values)\n",
    "        for idx, particle_number in enumerate(particle_index_trackpy_values):\n",
    "            t_filtered.loc[t_filtered['particle'] == particle_number, 'particle'] = - (idx+1)\n",
    "        t_filtered['particle'] = t_filtered['particle'].abs()        \n",
    "        trajectory_length =  np.array( [len(t_filtered.loc[t_filtered['particle'] == i, 'frame'].values) for i in range(1, t_filtered['particle'].nunique()+1  )] )\n",
    "        metric =  np.mean(area_every_frame) * np.sum(trajectory_length) * num_detected_cells\n",
    "        #metric =   np.sum(trajectory_length) * num_detected_cells\n",
    "    except:\n",
    "        num_detected_cells = 0\n",
    "        t_filtered = pd.DataFrame([], columns=['frame', 'y', 'x'])\n",
    "        metric = 0\n",
    "        \n",
    "    if (masks_with_trackpy_labels == True) and (num_detected_cells>0) :\n",
    "        masks= convert_mask_labels (masks=masks_for_all_frames,tracking_dataframe=t_filtered)\n",
    "        t_filtered.rename(columns={\"particle\": \"Cell_ID\"}, inplace=True)\n",
    "    else:\n",
    "        masks= masks_for_all_frames        \n",
    "    return metric, masks, t_filtered, image_test,num_detected_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c6e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization code\n",
    "# detected_cells_matrix = np.zeros((int_threshold_vector.shape[0],cell_size_vector.shape[0] ) )\n",
    "# for index_intensity, intensity_value in enumerate(tqdm(int_threshold_vector)):\n",
    "#     for index_cell_size, cell_size in enumerate(cell_size_vector):\n",
    "#         detected_cells_matrix[index_intensity,index_cell_size],_,_,_,_ = cell_segmentation_optimized (image_to_segment=image_optimization, intensity_percentile_threshold=intensity_value,cell_size=cell_size,model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9211b0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detected_cells_matrix = np.zeros((int_threshold_vector.shape[0],) )\n",
    "# for index_intensity, intensity_value in enumerate(tqdm(int_threshold_vector)):\n",
    "#     detected_cells_matrix[index_intensity],_,_,_ = cell_segmentation_optimized (image_to_segment=image_optimization, model=model, intensity_percentile_threshold=intensity_value,use_cellpose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ec0ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the numpy array\n",
    "#np.save('detected_cells_matrix.npy', detected_cells_matrix)\n",
    "#np.save('int_threshold_vector.npy', int_threshold_vector)\n",
    "#np.save('cell_size_vector.npy', cell_size_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82396ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the numpy array\n",
    "detected_cells_matrix = np.load('detected_cells_matrix.npy') \n",
    "int_threshold_vector = np.load('int_threshold_vector.npy') \n",
    "cell_size_vector = np.load('cell_size_vector.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20005c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing optimization plot\n",
    "tick_values= np.linspace(0, number_optimization_steps,num=number_optimization_steps,endpoint=False)\n",
    "df_optimization = pd.DataFrame(detected_cells_matrix ) # Converting the image into a pandas data frame\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "sn.heatmap(df_optimization, annot=True,cmap=\"Spectral\",ax=ax)\n",
    "ax.set_xlabel('cell size')\n",
    "ax.set_ylabel('intensity')\n",
    "ax.set_yticks(tick_values,int_threshold_vector)  \n",
    "ax.set_xticks(tick_values,cell_size_vector)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7edf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running for selected values\n",
    "selected_intensity_index, selected_cell_size_index = unravel_index(detected_cells_matrix.argmax(), detected_cells_matrix.shape)\n",
    "metric, masks_final, cell_movement_dataframe,image_optimization_selected,number_cells = cell_segmentation_optimized (image_to_segment=image_optimization, \n",
    "                                                                                                                intensity_percentile_threshold=int_threshold_vector[selected_intensity_index],\n",
    "                                                                                                                cell_size=cell_size_vector[selected_cell_size_index], model=model ,\n",
    "                                                                                                                masks_with_trackpy_labels= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd3949",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int_threshold_vector[selected_intensity_index], cell_size_vector[selected_cell_size_index], int(metric), number_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a53fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4142 189 15\n",
    "# metric, masks_final, cell_movement_dataframe,image_optimization_selected, number_cells = cell_segmentation_optimized (image_to_segment=image_optimization, \n",
    "#                                                                                                                 intensity_percentile_threshold=1.5,\n",
    "#                                                                                                                 cell_size=116, \n",
    "#                                                                                                                 model=model ,\n",
    "#                                                                                                                 masks_with_trackpy_labels= True)\n",
    "# print(int_threshold_vector[selected_intensity_index], cell_size_vector[selected_cell_size_index], metric, number_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aef224",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_columns = 15\n",
    "number_images = masks_final.shape[0]\n",
    "number_rows = math.ceil(number_images/number_columns)\n",
    "individual_figure_size = 2\n",
    "# Loop to plot multiple cells in a grid\n",
    "gs = gridspec.GridSpec(number_rows, number_columns)\n",
    "gs.update(wspace = 0.1, hspace = 0.1) # set the spacing between axes.\n",
    "fig = plt.figure(figsize = (individual_figure_size*number_columns, individual_figure_size*number_rows))\n",
    "for index_image in range(0, number_images):\n",
    "    ax = fig.add_subplot(gs[index_image])\n",
    "    ax.imshow(masks_final[index_image], cmap = 'tab20',vmin=0,vmax=masks_final.max())\n",
    "    ax.set_xticks([]); ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ac6d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_columns = 15\n",
    "number_images = image_optimization_selected.shape[0]\n",
    "number_rows = math.ceil(number_images/number_columns)\n",
    "individual_figure_size = 2\n",
    "# intensity\n",
    "\n",
    "# Loop to plot multiple cells in a grid\n",
    "gs = gridspec.GridSpec(number_rows, number_columns)\n",
    "gs.update(wspace = 0.1, hspace = 0.1) # set the spacing between axes.\n",
    "fig = plt.figure(figsize = (individual_figure_size*number_columns, individual_figure_size*number_rows))\n",
    "for index_image in range(0, number_images):\n",
    "    ax = fig.add_subplot(gs[index_image])\n",
    "    ax.imshow(image_optimization_selected[index_image,:,:,0], cmap = 'Spectral',vmin=image_optimization_selected[:,:,:,0].min(),vmax=image_optimization_selected[:,:,:,0].max())\n",
    "    ax.set_xticks([]); ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e0feee",
   "metadata": {},
   "source": [
    "### Plotting the spots in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe25d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_masks(index_frame=0):\n",
    "    \n",
    "    cells_ids = np.unique(cell_movement_dataframe['Cell_ID'].values)\n",
    "    centers_mass = [cell_movement_dataframe.loc[(cell_movement_dataframe['Cell_ID']==selected_cell) & (cell_movement_dataframe['frame']==index_frame) ,['x','y','Cell_ID']].values for _,selected_cell in enumerate(cells_ids) ]\n",
    "    array_center_mass = np.array ( [ele for ele in centers_mass if len(ele) >0])[:,0,:]\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2,figsize=(10,5))\n",
    "    # plotting real image\n",
    "    ax[0].imshow(image_optimization[index_frame,:,:,0], cmap = 'Spectral_r')\n",
    "    ax[0].set_title('Frame '+ str(index_frame))\n",
    "    ax[0].set_xticks([]); ax[0].set_yticks([])\n",
    "    \n",
    "    # plotting masks\n",
    "    ax[1].imshow(masks_final[index_frame], cmap = 'tab20',vmin=0,vmax=masks_final.max())\n",
    "    ax[1].set_title('Frame '+ str(index_frame))\n",
    "    ax[1].set_xticks([]); ax[1].set_yticks([])\n",
    "    for i,cell in enumerate(array_center_mass[:,2]):\n",
    "        x_val = array_center_mass[i,0]\n",
    "        y_val = array_center_mass[i,1]\n",
    "        ax[1].text(x=x_val-10, y=y_val-10, s=str(array_center_mass[i,2]), fontsize=12, color=\"Black\" )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704e6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_frame = widgets.IntSlider(value=0, min=0,max=masks_final.shape[0]-1,step=1, description='Frame:')\n",
    "widgets.interact(plotting_masks, index_frame=index_frame);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce39193",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e63bf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658f9df8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e056465",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d5506d",
   "metadata": {},
   "source": [
    "## Plotting cell labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf301b",
   "metadata": {},
   "source": [
    "## Detecting spots in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8848f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test=image_optimization[:,:,:,0].copy()\n",
    "image_test[image_test>np.percentile(image_test,99)]=np.percentile(image_test,99)  # threshold image values larger than 1000 equal to 1000\n",
    "filtered_img = rsp.Utilities.log_filter(image=image_test, sigma=1)\n",
    "print('filtered image shape ', filtered_img.shape)\n",
    "print('filtered image range ', filtered_img.min(), filtered_img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0ebae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_filtered_image(index_frame=0):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "    # plotting real image\n",
    "    ax.imshow(filtered_img[index_frame], cmap = 'Spectral_r')\n",
    "    ax.set_title('Frame '+ str(index_frame))\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ef882",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_frame = widgets.IntSlider(value=0, min=0,max=masks_final.shape[0]-1,step=1, description='Frame:')\n",
    "widgets.interact(plotting_filtered_image, index_frame=index_frame);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055d2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_percentile_to_detect_spots = 70\n",
    "preprocess_image_for_tracking = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6fdb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section generates an histogram with the intensity of the detected particles in the video.\n",
    "\n",
    "particle_size = 7 # according to the documentation must be an odd number 3,5,7,9 etc.\n",
    "minimal_intensity_for_selection = 0 # minimal intensity to detect a particle.\n",
    "\n",
    "# \"f\" is a pandas data freame that contains the information about the detected spots\n",
    "f = tp.locate(filtered_img[0,:,:], particle_size, minmass=minimal_intensity_for_selection,percentile=selected_percentile_to_detect_spots,preprocess=preprocess_image_for_tracking) \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(f['mass'], bins=100, color = \"orangered\", ec=\"orangered\")\n",
    "ax.set(xlabel='mass', ylabel='count')\n",
    "ax.set_ylim([0,200])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cbdc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section generates an histogram with the intensity of the detected particles in the video.\n",
    "\n",
    "particle_size = 7 # according to the documentation must be an odd number 3,5,7,9 etc.\n",
    "minimal_intensity_for_selection = 3000 # minimal intensity to detect a particle.\n",
    "# \"f\" is a pandas data frame that contains the information about the detected spots\n",
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "\n",
    "f = tp.locate(filtered_img[0,:,:], particle_size, minmass=minimal_intensity_for_selection,percentile=selected_percentile_to_detect_spots,preprocess=preprocess_image_for_tracking) \n",
    "tp.annotate(f,filtered_img[0,:,:],ax=ax); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f61cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To start visualization move the time slider.\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5) # if movie is too big, change size to (7,7)\n",
    "def figure_viewer_tr(time,mass_text, particle_size):\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "    ch = 0  \n",
    "    f = tp.locate(filtered_img[time],particle_size, minmass=mass_text, maxsize=7, percentile=selected_percentile_to_detect_spots,preprocess=preprocess_image_for_tracking) # \"f\" is a pandas data frame that contains the information about the detected spots\n",
    "    tp.annotate(f,filtered_img[time],ax=ax) # tp.annotate is a trackpy function that displays the image with the detected spots  \n",
    "values_size=[3,5,7,9] # Notice value must be an odd number.\n",
    "interactive_plot_tr = interactive(figure_viewer_tr, mass_text = widgets.IntSlider(value=3000,min=1000,max=10000,description='min Intensity'), particle_size = widgets.IntSlider(min=3,max=11,step=2,value=7,description='Particle Size'), time = widgets.IntSlider(min=0,max=video.shape[0]-1,step=1,value=0,description='Time'))\n",
    "controls = HBox(interactive_plot_tr.children[:-1], layout = Layout(flex_flow='row wrap'))\n",
    "output = interactive_plot_tr.children[-1]\n",
    "display(VBox([controls, output])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605d9760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section saves the parameters adjusted in the previous widget in two variables that will be use for the rest of the code.\n",
    "selected_intensity = interactive_plot_tr.kwargs_widgets[1].value\n",
    "selected_size = interactive_plot_tr.kwargs_widgets[2].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b71711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"f\" is a pandas data frame that contains the information about the detected spots.\n",
    "# tp.batch is a trackpy function that detects spots for multiple frames in a video.\n",
    "f = tp.batch(frames = filtered_img, diameter = selected_size, minmass = selected_intensity,percentile=selected_percentile_to_detect_spots,preprocess=preprocess_image_for_tracking)\n",
    "#f = tp.batch(frames = filtered_img,kwargs = {'raw_image' : image_optimization[:,:,:,0]}, diameter = selected_size, minmass = selected_intensity,percentile=selected_percentile_to_detect_spots,preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f55ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499d9dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spots_in_mask(f, masks):\n",
    "    f_test=f.copy()\n",
    "    f_test['Cell_ID'] = 0\n",
    "    frames_in_dataframe = np.unique(f_test['frame'].values)\n",
    "    for _, selected_frame in enumerate(frames_in_dataframe):\n",
    "        selected_frame_masks= masks[selected_frame]\n",
    "        selected_dataframe = f_test.loc[f_test['frame']==selected_frame]\n",
    "        coords_int = np.array([selected_dataframe.y, selected_dataframe.x], dtype= int).T # These are the points detected by trackpy\n",
    "        values_at_coords = selected_frame_masks[tuple(coords_int.T)] #\n",
    "        f_test.loc[f_test['frame']==selected_frame ,'Cell_ID'] = values_at_coords.T # Check if pts are on/in polygon mask  \n",
    "        del selected_frame_masks, selected_dataframe, coords_int, values_at_coords\n",
    "    return f_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410d8719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = spots_in_mask(f, masks_final) \n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cc9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final[df_final['Cell_ID']>0] # removing spots outside masks\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0fb8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_search_range = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c36bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_ids = np.unique(df_final['Cell_ID'].values)\n",
    "list_df_cells =[]\n",
    "for _, selected_cell in enumerate(cells_ids):\n",
    "    df_selected_cell = df_final[df_final['Cell_ID']==selected_cell] # removing spots outside masks\n",
    "    linked_dataframe = tp.link(df_selected_cell,search_range=maximum_search_range, memory=1)\n",
    "    filtered_dataframe = tp.filter_stubs(linked_dataframe, 10)\n",
    "    if len(filtered_dataframe)>0:\n",
    "        list_df_cells.append(filtered_dataframe ) # selecting trajectories that appear in at least 10 frames.\n",
    "    del linked_dataframe, df_selected_cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0538dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp = pd.DataFrame(data = None, columns= df_final.columns)\n",
    "dfp = pd.concat(list_df_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c138cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d121b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cells_ids = np.unique(df_final['Cell_ID'].values)\n",
    "\n",
    "for _, selected_cell in enumerate(cells_ids):\n",
    "    print('Cell_ID: ', selected_cell)\n",
    "    array_particle_ids = np.unique(dfp.loc[dfp['Cell_ID'] == selected_cell, 'particle'].values)\n",
    "    for _,particle_id in enumerate (array_particle_ids):\n",
    "        frames_in_spot = dfp.loc[  (dfp['particle']==particle_id) &  (dfp['Cell_ID']==selected_cell) ].frame.values\n",
    "        particle_intensity_in_spot =  dfp.loc[  (dfp['particle']==particle_id) &  (dfp['Cell_ID']==selected_cell) ].mass.values\n",
    "        plt.plot(frames_in_spot,particle_intensity_in_spot)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b53a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the number of detected spots.\n",
    "n_particles = dfp['particle'].nunique()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(20,5))\n",
    "\n",
    "# plotting intensities in au\n",
    "for id in range(0,n_particles):\n",
    "    plt.plot(dfp.loc[dfp['particle']==dfp['particle'].unique()[id]].frame, dfp.loc[dfp['particle']==dfp['particle'].unique()[id]].mass )\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Intensity a.u.')\n",
    "plt.title('Intensity vs Time')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcf0116",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(10,10))\n",
    "ch = 0  \n",
    "time =30\n",
    "tp.annotate(dfp,filtered_img[time],ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6913b536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd8e331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c48160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399e44f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('rsnaped_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "daf7c258a197027f92a823c5e9002157216e53cdde30f9077602d149eebf1043"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
